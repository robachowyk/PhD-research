{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import textdistance\n",
    "import timeit\n",
    "import pandas as pds\n",
    "from sklearn import mixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_DF = 'DF_associations_N=43889_2023-01-03.csv'\n",
    "# COMPLETE identifiers = {'name':'jaro-winkler','family name':'jaro-winkler','gender':'strict','country':'strict','birth year':'large'}\n",
    "identifiers = {'family name':'jaro-winkler','gender':'strict','country':'strict','birth year':'large'}\n",
    "covariates = ['X1','X2','X3','X4','X5']\n",
    "\n",
    "DF = pds.read_csv(os.path.join('..', name_DF), delimiter = ',')\n",
    "\n",
    "overlap = DF.sample(n = 150)\n",
    "\n",
    "A = pds.concat([DF.sample(n = 450), overlap]).drop(['Y'], axis = 1)\n",
    "A = A.reset_index(drop=True)\n",
    "\n",
    "B = pds.concat([DF.sample(n = 350), overlap])[list(identifiers.keys())+['Y']]\n",
    "B = B.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>family name</th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "      <th>birth year</th>\n",
       "      <th>treatment</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ariane</td>\n",
       "      <td>Hausmann</td>\n",
       "      <td>F</td>\n",
       "      <td>DE</td>\n",
       "      <td>1978</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.368755</td>\n",
       "      <td>3.970096</td>\n",
       "      <td>8.963813</td>\n",
       "      <td>-0.040154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robert</td>\n",
       "      <td>Kycia</td>\n",
       "      <td>M</td>\n",
       "      <td>PL</td>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>5.162158</td>\n",
       "      <td>4.167418</td>\n",
       "      <td>9.086824</td>\n",
       "      <td>0.533097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gökhan</td>\n",
       "      <td>Subatan</td>\n",
       "      <td>M</td>\n",
       "      <td>BE</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>4.150520</td>\n",
       "      <td>3.864387</td>\n",
       "      <td>9.262914</td>\n",
       "      <td>0.798250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ilaria</td>\n",
       "      <td>Campanale</td>\n",
       "      <td>F</td>\n",
       "      <td>IT</td>\n",
       "      <td>1953</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>6.450749</td>\n",
       "      <td>3.525062</td>\n",
       "      <td>9.163808</td>\n",
       "      <td>0.216214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nathalie</td>\n",
       "      <td>Kunkel</td>\n",
       "      <td>F</td>\n",
       "      <td>DE</td>\n",
       "      <td>1978</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1.633013</td>\n",
       "      <td>3.099963</td>\n",
       "      <td>9.500583</td>\n",
       "      <td>1.822581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name family name gender country  birth year  treatment  X1        X2  \\\n",
       "0    Ariane    Hausmann      F      DE        1978          0  42  1.368755   \n",
       "1    Robert       Kycia      M      PL        1976          0  44  5.162158   \n",
       "2    Gökhan     Subatan      M      BE        1993          1  27  4.150520   \n",
       "3    Ilaria   Campanale      F      IT        1953          0  67  6.450749   \n",
       "4  Nathalie      Kunkel      F      DE        1978          1  42  1.633013   \n",
       "\n",
       "         X3        X4        X5  \n",
       "0  3.970096  8.963813 -0.040154  \n",
       "1  4.167418  9.086824  0.533097  \n",
       "2  3.864387  9.262914  0.798250  \n",
       "3  3.525062  9.163808  0.216214  \n",
       "4  3.099963  9.500583  1.822581  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family name</th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "      <th>birth year</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nicolini</td>\n",
       "      <td>F</td>\n",
       "      <td>IT</td>\n",
       "      <td>1963</td>\n",
       "      <td>52.519435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ouaras</td>\n",
       "      <td>F</td>\n",
       "      <td>FR</td>\n",
       "      <td>1962</td>\n",
       "      <td>51.541661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Holl</td>\n",
       "      <td>F</td>\n",
       "      <td>IT</td>\n",
       "      <td>1963</td>\n",
       "      <td>-4.559265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sh</td>\n",
       "      <td>F</td>\n",
       "      <td>DE</td>\n",
       "      <td>1957</td>\n",
       "      <td>59.016003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nikolopoulos</td>\n",
       "      <td>M</td>\n",
       "      <td>GR</td>\n",
       "      <td>1958</td>\n",
       "      <td>-3.467832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    family name gender country  birth year          Y\n",
       "0      Nicolini      F      IT        1963  52.519435\n",
       "1        Ouaras      F      FR        1962  51.541661\n",
       "2          Holl      F      IT        1963  -4.559265\n",
       "3            Sh      F      DE        1957  59.016003\n",
       "4  Nikolopoulos      M      GR        1958  -3.467832"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_similarity(a,b):\n",
    "\n",
    "    \"\"\" Check that levenshtein similarity (in [0,1]) is above 0.95.\n",
    "        \n",
    "        a: string,\n",
    "        b: string \"\"\"\n",
    "\n",
    "    if 1 - textdistance.levenshtein(a, b)/max(len(a),len(b)) >= 0.95:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def jaro_winkler_similarity(a,b):\n",
    "\n",
    "    \"\"\" Check that jaro-winkler similarity (in [0,1]) is above 0.95.\n",
    "        \n",
    "        a: string,\n",
    "        b: string \"\"\"\n",
    "\n",
    "    if textdistance.jaro_winkler(a,b) >= 0.95:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def strict_equality(a,b):\n",
    "\n",
    "    \"\"\" Check that a and b values are equal.\n",
    "        \n",
    "        a: any value,\n",
    "        b: any value \"\"\"\n",
    "\n",
    "    return a==b\n",
    "\n",
    "def large_equality(a,b):\n",
    "\n",
    "    \"\"\" Check that years a and b expressed with four numbers are within the same decade.\n",
    "        \n",
    "        a: year,\n",
    "        b: year \"\"\"\n",
    "\n",
    "    return str(a)[:-1]==str(b)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def comparison_vector(A_record, B, identifiers):\n",
    "    \n",
    "    \"\"\" Compare one record in A with all records in B. \n",
    "        Return the binary comparison of the identifiers for one record in A with all records in B.\n",
    "\n",
    "        A_record:     series of one row, \n",
    "        B:            dataframe, \n",
    "        identifiers:  dict: k = column name, \n",
    "                            v = method in {'large','strict','levenshtein','jaro-winkler'}\n",
    "    \"\"\"\n",
    "\n",
    "    methods = {'jaro-winkler':jaro_winkler_similarity, 'levenshtein':levenshtein_similarity, 'strict':strict_equality, 'large':large_equality}\n",
    "    comparisons = {}\n",
    "    for linking_var in identifiers:\n",
    "        method = methods[identifiers[linking_var]]\n",
    "        comparisons[linking_var] = np.array(B.apply(lambda row: method(A_record[linking_var], row[linking_var]), axis=1)).reshape(-1,1)\n",
    "    return np.concatenate(tuple(comparisons.values()), axis = 1) \n",
    "    \n",
    "A_record = A.iloc[0,:]\n",
    "comparison_vector(A_record, B, identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Int64Index([488, 388], dtype='int64')\n",
      " Int64Index([561, 461], dtype='int64')\n",
      " Int64Index([599, 499], dtype='int64')\n",
      " Int64Index([512, 412], dtype='int64')\n",
      " Int64Index([593, 493], dtype='int64')\n",
      " Int64Index([548, 448], dtype='int64')\n",
      " Int64Index([463, 363], dtype='int64')\n",
      " Int64Index([584, 484], dtype='int64')\n",
      " Int64Index([485, 385], dtype='int64')\n",
      " Int64Index([507, 407], dtype='int64')\n",
      " Int64Index([501, 401], dtype='int64')\n",
      " Int64Index([581, 481], dtype='int64')\n",
      " Int64Index([580, 480], dtype='int64')\n",
      " Int64Index([585, 485], dtype='int64')\n",
      " Int64Index([482, 382], dtype='int64')\n",
      " Int64Index([546, 446], dtype='int64')\n",
      " Int64Index([451, 351], dtype='int64')\n",
      " Int64Index([538, 438], dtype='int64')\n",
      " Int64Index([590, 490], dtype='int64')\n",
      " Int64Index([564, 464], dtype='int64')\n",
      " Int64Index([553, 453], dtype='int64')\n",
      " Int64Index([578, 478], dtype='int64')\n",
      " Int64Index([588, 488], dtype='int64')\n",
      " Int64Index([456, 356], dtype='int64')\n",
      " Int64Index([583, 483], dtype='int64')\n",
      " Int64Index([596, 496], dtype='int64')\n",
      " Int64Index([525, 425], dtype='int64')\n",
      " Int64Index([533, 433], dtype='int64')\n",
      " Int64Index([555, 455], dtype='int64')\n",
      " Int64Index([489, 389], dtype='int64')\n",
      " Int64Index([595, 495], dtype='int64')\n",
      " Int64Index([464, 364], dtype='int64')\n",
      " Int64Index([511, 411], dtype='int64')\n",
      " Int64Index([516, 416], dtype='int64')\n",
      " Int64Index([552, 452], dtype='int64')\n",
      " Int64Index([569, 469], dtype='int64')\n",
      " Int64Index([527, 427], dtype='int64')\n",
      " Int64Index([562, 462], dtype='int64')\n",
      " Int64Index([523, 423], dtype='int64')\n",
      " Int64Index([571, 471], dtype='int64')\n",
      " Int64Index([577, 477], dtype='int64')\n",
      " Int64Index([558, 458], dtype='int64')\n",
      " Int64Index([542, 442], dtype='int64')\n",
      " Int64Index([494, 394], dtype='int64')\n",
      " Int64Index([591, 491], dtype='int64')\n",
      " Int64Index([479, 379], dtype='int64')\n",
      " Int64Index([473, 373], dtype='int64')\n",
      " Int64Index([587, 487], dtype='int64')\n",
      " Int64Index([544, 444], dtype='int64')\n",
      " Int64Index([589, 489], dtype='int64')\n",
      " Int64Index([474, 374], dtype='int64')\n",
      " Int64Index([518, 418], dtype='int64')\n",
      " Int64Index([597, 497], dtype='int64')\n",
      " Int64Index([467, 367], dtype='int64')\n",
      " Int64Index([537, 437], dtype='int64')\n",
      " Int64Index([508, 408], dtype='int64')\n",
      " Int64Index([503, 403], dtype='int64')\n",
      " Int64Index([598, 498], dtype='int64')\n",
      " Int64Index([457, 357], dtype='int64')\n",
      " Int64Index([528, 428], dtype='int64')\n",
      " Int64Index([500, 400], dtype='int64')\n",
      " Int64Index([460, 360], dtype='int64')\n",
      " Int64Index([549, 449], dtype='int64')\n",
      " Int64Index([530, 430], dtype='int64')\n",
      " Int64Index([476, 376], dtype='int64')\n",
      " Int64Index([478, 378], dtype='int64')\n",
      " Int64Index([506, 406], dtype='int64')\n",
      " Int64Index([502, 402], dtype='int64')\n",
      " Int64Index([572, 472], dtype='int64')\n",
      " Int64Index([499, 399], dtype='int64')\n",
      " Int64Index([568, 468], dtype='int64')\n",
      " Int64Index([579, 479], dtype='int64')\n",
      " Int64Index([486, 386], dtype='int64')\n",
      " Int64Index([509, 409], dtype='int64')\n",
      " Int64Index([582, 482], dtype='int64')\n",
      " Int64Index([554, 454], dtype='int64')\n",
      " Int64Index([515, 415], dtype='int64')\n",
      " Int64Index([566, 466], dtype='int64')\n",
      " Int64Index([557, 457], dtype='int64')\n",
      " Int64Index([510, 410], dtype='int64')\n",
      " Int64Index([417, 266], dtype='int64')\n",
      " Int64Index([491, 391], dtype='int64')\n",
      " Int64Index([526, 426], dtype='int64')\n",
      " Int64Index([534, 434], dtype='int64')\n",
      " Int64Index([32, 312], dtype='int64')\n",
      " Int64Index([522, 422], dtype='int64')\n",
      " Int64Index([472, 372], dtype='int64')\n",
      " Int64Index([567, 467], dtype='int64')\n",
      " Int64Index([481, 381], dtype='int64')\n",
      " Int64Index([563, 463], dtype='int64')\n",
      " Int64Index([492, 392], dtype='int64')\n",
      " Int64Index([540, 440], dtype='int64')\n",
      " Int64Index([477, 377], dtype='int64')\n",
      " Int64Index([576, 476], dtype='int64')\n",
      " Int64Index([487, 387], dtype='int64')\n",
      " Int64Index([455, 355], dtype='int64')\n",
      " Int64Index([536, 436], dtype='int64')\n",
      " Int64Index([475, 375], dtype='int64')\n",
      " Int64Index([539, 439], dtype='int64')\n",
      " Int64Index([462, 362], dtype='int64')\n",
      " Int64Index([490, 390], dtype='int64')\n",
      " Int64Index([459, 359], dtype='int64')\n",
      " Int64Index([504, 404], dtype='int64')\n",
      " Int64Index([573, 473], dtype='int64')\n",
      " Int64Index([529, 429], dtype='int64')\n",
      " Int64Index([497, 397], dtype='int64')\n",
      " Int64Index([556, 456], dtype='int64')\n",
      " Int64Index([520, 420], dtype='int64')\n",
      " Int64Index([543, 443], dtype='int64')\n",
      " Int64Index([574, 474], dtype='int64')\n",
      " Int64Index([547, 447], dtype='int64')\n",
      " Int64Index([586, 486], dtype='int64')\n",
      " Int64Index([454, 354], dtype='int64')\n",
      " Int64Index([531, 431], dtype='int64')\n",
      " Int64Index([541, 441], dtype='int64')\n",
      " Int64Index([458, 358], dtype='int64')\n",
      " Int64Index([517, 417], dtype='int64')\n",
      " Int64Index([545, 445], dtype='int64')\n",
      " Int64Index([524, 424], dtype='int64')\n",
      " Int64Index([471, 371], dtype='int64')\n",
      " Int64Index([575, 475], dtype='int64')\n",
      " Int64Index([498, 398], dtype='int64')\n",
      " Int64Index([592, 492], dtype='int64')\n",
      " Int64Index([551, 451], dtype='int64')\n",
      " Int64Index([513, 413], dtype='int64')\n",
      " Int64Index([468, 368], dtype='int64')\n",
      " Int64Index([483, 383], dtype='int64')\n",
      " Int64Index([71, 160], dtype='int64')\n",
      " Int64Index([521, 421], dtype='int64')\n",
      " Int64Index([484, 384], dtype='int64')\n",
      " Int64Index([461, 361], dtype='int64')\n",
      " Int64Index([495, 395], dtype='int64')\n",
      " Int64Index([535, 435], dtype='int64')\n",
      " Int64Index([514, 414], dtype='int64')\n",
      " Int64Index([453, 353], dtype='int64')\n",
      " Int64Index([496, 396], dtype='int64')\n",
      " Int64Index([550, 450], dtype='int64')\n",
      " Int64Index([532, 432], dtype='int64')\n",
      " Int64Index([465, 365], dtype='int64')\n",
      " Int64Index([466, 366], dtype='int64')\n",
      " Int64Index([505, 405], dtype='int64')\n",
      " Int64Index([559, 459], dtype='int64')\n",
      " Int64Index([470, 370], dtype='int64')\n",
      " Int64Index([493, 393], dtype='int64')\n",
      " Int64Index([480, 380], dtype='int64')\n",
      " Int64Index([560, 460], dtype='int64')\n",
      " Int64Index([469, 369], dtype='int64')\n",
      " Int64Index([450, 350], dtype='int64') Int64Index([91, 14], dtype='int64')\n",
      " Int64Index([519, 419], dtype='int64')\n",
      " Int64Index([594, 494], dtype='int64')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A': array([488, 561, 599, 512, 593, 548, 463, 584, 485, 507, 501, 581, 580,\n",
       "        585, 482, 546, 451, 538, 590, 564, 553, 578, 588, 456, 583, 596,\n",
       "        525, 533, 555, 489, 595, 464, 511, 516, 552, 569, 527, 562, 523,\n",
       "        571, 577, 558, 542, 494, 591, 479, 473, 587, 544, 589, 474, 518,\n",
       "        597, 467, 537, 508, 503, 598, 457, 528, 500, 460, 549, 530, 476,\n",
       "        478, 506, 502, 572, 499, 568, 579, 486, 509, 582, 554, 515, 566,\n",
       "        557, 510, 417, 491, 526, 534,  32, 522, 472, 567, 481, 563, 492,\n",
       "        540, 477, 576, 487, 455, 536, 475, 539, 462, 490, 459, 504, 573,\n",
       "        529, 497, 556, 520, 543, 574, 547, 586, 454, 531, 541, 458, 517,\n",
       "        545, 524, 471, 575, 498, 592, 551, 513, 468, 483,  71, 521, 484,\n",
       "        461, 495, 535, 514, 453, 496, 550, 532, 465, 466, 505, 559, 470,\n",
       "        493, 480, 560, 469, 450,  91, 519, 594]),\n",
       " 'B': array([388, 461, 499, 412, 493, 448, 363, 484, 385, 407, 401, 481, 480,\n",
       "        485, 382, 446, 351, 438, 490, 464, 453, 478, 488, 356, 483, 496,\n",
       "        425, 433, 455, 389, 495, 364, 411, 416, 452, 469, 427, 462, 423,\n",
       "        471, 477, 458, 442, 394, 491, 379, 373, 487, 444, 489, 374, 418,\n",
       "        497, 367, 437, 408, 403, 498, 357, 428, 400, 360, 449, 430, 376,\n",
       "        378, 406, 402, 472, 399, 468, 479, 386, 409, 482, 454, 415, 466,\n",
       "        457, 410, 266, 391, 426, 434, 312, 422, 372, 467, 381, 463, 392,\n",
       "        440, 377, 476, 387, 355, 436, 375, 439, 362, 390, 359, 404, 473,\n",
       "        429, 397, 456, 420, 443, 474, 447, 486, 354, 431, 441, 358, 417,\n",
       "        445, 424, 371, 475, 398, 492, 451, 413, 368, 383, 160, 421, 384,\n",
       "        361, 395, 435, 414, 353, 396, 450, 432, 365, 366, 405, 459, 370,\n",
       "        393, 380, 460, 369, 350,  14, 419, 494])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def almost_exact_matches(A, B, compare_on):\n",
    "    \n",
    "    \"\"\" Compare A records and B records.\n",
    "        Return the exact common records (where all identifiers are equals).\n",
    "        Be aware that these record are not clearly exact matches in reality (if we do not have name + family name + birth date as identifiers for example).\n",
    "\n",
    "        A: dataframe, \n",
    "        B: dataframe,\n",
    "        identifiers:  dict: k = column name, \n",
    "                            v = method in {'large','strict','levenshtein','jaro-winkler'}\n",
    "    \"\"\"\n",
    "\n",
    "    A['source'] = 'A'\n",
    "    B['source'] = 'B'\n",
    "    # we remove A and B duplicates to ensure returning 1-2-1 true matches:\n",
    "    df = pds.concat([A[~A[identifiers.keys()].duplicated(keep=False)],B[~B[identifiers.keys()].duplicated(keep=False)]], join='inner')\n",
    "    duplicata = df[df[compare_on.keys()].duplicated(keep=False)]\n",
    "    duplicata = np.array(duplicata.groupby(list(df[compare_on.keys()])).apply(lambda row: row.index))\n",
    "    print(duplicata)\n",
    "    return {'A':np.array([idx[0] for idx in duplicata]), 'B':np.array([idx[1] for idx in duplicata])}\n",
    "\n",
    "almost_exact_matches(A, B, identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# match: probability of having same linking var when being true matches\n",
    "# unmatch: probability of having same linking var (at all)\n",
    "\n",
    "match = np.repeat(0.95, len(identifiers.keys()))\n",
    "unmatch = A.apply(lambda row: comparison_vector(row, B, identifiers).sum(axis=0), axis=1).sum() / (A.shape[0]*B.shape[0]) # for each A record and for each linking variable, we check 'the probability' to match (over the nA * nB pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "        260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "        286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "        299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "        377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "        403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "        416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "        429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "        442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "        455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
       "        481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
       "        494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
       "        507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
       "        520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
       "        533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
       "        546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
       "        559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
       "        572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
       "        585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
       "        598, 599]),\n",
       " 'B': array([  5,  34, 497, 323,   5,   1,  68,   5,   5,  97,  17,   4,  24,\n",
       "          7,  25, 106, 296,  24,  12,  39, 146, 143,   5, 135, 160,  17,\n",
       "         53,  25,   0,   7,  24,  12, 312, 320,   7, 352,   3,  23, 250,\n",
       "          3, 173,   5,   7,  17,   8, 136,  15,   5,  12, 388,  53,  12,\n",
       "         12,  12, 231,  12,   5,   8, 341,   7,  25,   6,   5, 331,  53,\n",
       "          5,   5,   9,  12, 332, 134, 160, 238,  30,  14,  68,  44,  15,\n",
       "         17,  12, 173,   5, 238,  53,  23, 266,  15,   7,  17,  53,  12,\n",
       "         14,   5,  14,   5,  12, 146,  24,  12, 343,  12, 444,  24,   5,\n",
       "         12,   7,  23,  17,  12,  25,  91,   8,  24,   1,  12,   5,  68,\n",
       "          7, 261,  53,   4,  25,  25,  24,  53,  24,  15,  67,  12,  12,\n",
       "         12,  12,  14,  12,   3,  24,  25,   5,  15, 143,  14, 261,  17,\n",
       "          3,   9,  12,  17, 238,  15,  12, 261,   5, 161,  24,  12,  53,\n",
       "         24,  33, 238, 238,  17,  25, 146,  15,  15,  17,  24, 266,   5,\n",
       "         12,  12,   0,  12,  12,  15,  24,  12,   5,   5,  58,  24, 146,\n",
       "        250,  19,   3,  23,  12,   5,  15, 470, 164, 323,  53,   9,  12,\n",
       "         12,  91, 143, 225,  12,  53,   5,  14, 143, 173,   9,  23,  53,\n",
       "          8,  63,  12,  17,  10,  12,   7, 143,   6,   3,  12, 495,  12,\n",
       "        495,  30,   8,   4,  52, 160,   4,  24,   7,  25, 146,  17,  17,\n",
       "         23,  24,  24,  12,   9,  17,  14, 238, 113,   1,  25,   5,  13,\n",
       "         68,   1,   5,  25,  12, 238,  12,   8,  25,  12,  15,  12,  15,\n",
       "         23,   3,   6, 384, 110,  10, 261,   8,  12,  12, 146,  12, 320,\n",
       "         24, 161,  17,  12,  17,  68,  95, 143,   8,   5,  15,   5,   7,\n",
       "         49,   5,  15,   9,  30, 146, 146, 377,  12,   5,  12,  23,  12,\n",
       "         12, 238,   5,  17,  68, 339,  25,  58,   8,  34,   5,   5,  23,\n",
       "         17,  15, 250,  17, 296,  12, 412,   1,  12,   8,   3, 136,   5,\n",
       "         17,  12,   6,  15,  17, 106,  15,  12,  14,   5, 101,  15, 160,\n",
       "        110,  68, 320,  52, 238,  19,   5, 377, 267,  12,  12,  68,  53,\n",
       "          7,  23,  68,  23,  18,  14,   5,   5,  24,   5,  15,  15,  39,\n",
       "          9,  33,   5, 134,  25,  24,  12,  15,  18,  12,  25,  14,  23,\n",
       "         23,  23,   8,   5,  24,  53,  12,  25, 296, 134,  12,   9, 289,\n",
       "        296,   1, 166,   5,   7,   5, 238, 296,  67,  12,  12,  12, 194,\n",
       "        135,   5, 173,  19, 239,  12,  23,   8,  15, 323,  12,   5,  24,\n",
       "         23, 266,   9,   5,  17,  12,  76,  34, 250,  23,  12,  97,  15,\n",
       "         24,  24, 134,  23,  49, 134,  15,   8, 238,   7,  52,  24,  14,\n",
       "         24,   5,   5,  68,   5, 238,  17,  67, 350, 351, 352, 353, 354,\n",
       "        355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
       "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
       "        381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
       "        394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
       "        407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
       "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
       "        433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
       "        446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
       "        459, 460, 461, 462, 463, 464, 241, 466, 467, 468, 469, 470, 471,\n",
       "        472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
       "        485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497,\n",
       "        498, 499]),\n",
       " 'scores': array([ 0.61151629,  0.61151629, -3.60721008,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629, -6.08754181,  0.61151629, -4.46920034,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629, -4.46920034,  0.61151629,\n",
       "         0.61151629,  0.61151629, 15.52959969,  0.61151629,  0.61151629,\n",
       "        15.52959969,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "        -3.60721008,  0.61151629, -4.46920034,  0.61151629, -3.60721008,\n",
       "        -4.46920034,  0.61151629,  0.61151629,  0.61151629, -3.60721008,\n",
       "         0.61151629,  0.61151629,  0.61151629, -6.08754181,  0.61151629,\n",
       "         0.61151629, -4.46920034,  0.61151629, -6.08754181, -4.46920034,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629, 15.52959969,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "        11.31087333,  0.61151629,  0.61151629,  0.61151629, -4.46920034,\n",
       "         0.61151629, 15.52959969,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629, -4.46920034,  0.61151629,  0.61151629,\n",
       "         0.61151629,  4.61181522,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629, -4.46920034,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "        -4.46920034,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629, -4.46920034,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  4.61181522,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629, -4.46920034,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629, 15.52959969,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629, 11.31087333,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629, -4.46920034,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629, -4.46920034,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "        -4.46920034,  0.61151629, -4.46920034,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "        -4.46920034,  0.61151629, -4.46920034,  0.61151629,  4.61181522,\n",
       "        -4.46920034,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  8.83054159,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629, -0.4689014 ,\n",
       "         0.61151629, -4.46920034,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629, -4.46920034,  3.74982496,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629, -4.46920034,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629, -4.46920034, -3.60721008,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629, -3.60721008,  0.61151629,\n",
       "         0.61151629,  0.61151629, -4.46920034,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         4.61181522,  0.61151629,  0.61151629, 11.31087333,  0.61151629,\n",
       "         0.61151629, -4.46920034,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629, -3.60721008,  0.61151629,  0.61151629, -4.46920034,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629, -4.46920034,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629, -4.46920034,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  8.83054159,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629, -3.60721008, -3.60721008,  0.61151629,\n",
       "         0.61151629,  0.61151629,  8.83054159,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629, -4.46920034, 15.52959969,  0.61151629, -4.46920034,\n",
       "         0.61151629,  0.61151629,  8.83054159,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629, -4.46920034,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629, -4.46920034, -4.46920034,\n",
       "        -4.46920034,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "         0.61151629,  0.61151629,  0.61151629,  0.61151629,  0.61151629,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969,\n",
       "        15.52959969, 15.52959969, 15.52959969, 15.52959969, 15.52959969])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linking_score(A, B, identifiers, match, unmatch):\n",
    "        \n",
    "    \"\"\" Compare records in A with records in B, computing all linking scores for records in A with records in B. \n",
    "        Return the indices of records in A with the best match index for record in B.\n",
    "\n",
    "        A:            dataframe, \n",
    "        B:            dataframe, \n",
    "        identifiers:  dict: k = column name, \n",
    "                            v = method in {'large','strict','levenshtein','jaro-winkler'}\n",
    "        match:        array of probabilities of having same linking variables when being a match,\n",
    "        unmatch:      array of probabilities of having same linking variables (at all, among the nA x nB pairs of record).\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_max_linking_score(A_record, B, identifiers, match, unmatch):\n",
    "        similarities = comparison_vector(A_record, B, identifiers)\n",
    "        linking_score = (np.multiply(similarities, np.log2(match/unmatch)) + np.multiply(1-similarities, np.log2((1-match)/(1-unmatch)))).sum(axis=1)\n",
    "        return linking_score.argmax(), linking_score.max()\n",
    "\n",
    "    links = A.apply(lambda row: compute_max_linking_score(row[list(identifiers.keys())], B, identifiers, match, unmatch), axis=1)\n",
    "    idx_in_A = np.arange(A.shape[0])\n",
    "    idx_in_B = np.array([element[0] for element in links])\n",
    "    matching_scores = np.array([element[1] for element in links])\n",
    "    return {'A':idx_in_A, 'B':idx_in_B, 'scores':matching_scores}\n",
    "\n",
    "linking_score(A, B, identifiers, match, unmatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43.855209924135366, 0.15908948881291174)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stratified_ATE(DF_group, pop_size):\n",
    "\n",
    "    \"\"\" Compute the Average Treatment Effect on the specific stratum represented in DF_group.\n",
    "\n",
    "        DF_group: dataframe. \n",
    "    \"\"\"\n",
    "\n",
    "    n_treated, n_untreated = DF_group[DF_group.treatment == 1].shape[0], DF_group[DF_group.treatment == 0].shape[0]\n",
    "    assert (n_treated!=0)&(n_untreated!=0), (\"One group among treated/untreated is empty with this stratification.\")\n",
    "    avg_outcome_treated = (DF_group.treatment * DF_group.Y).sum() / n_treated \n",
    "    avg_outcome_untreated = ((1 - DF_group.treatment) * DF_group.Y).sum() / n_untreated\n",
    "    var_treated = ( (DF_group.treatment * DF_group.Y - avg_outcome_treated)**2 ).sum() / (n_treated - 1)\n",
    "    var_untreated = ( ((1 - DF_group.treatment) * DF_group.Y - avg_outcome_untreated)**2 ).sum() / (n_untreated - 1)\n",
    "    size_group = DF_group.shape[0]\n",
    "    ATE_group = (size_group/pop_size) * (avg_outcome_treated - avg_outcome_untreated)\n",
    "    variance_group = (size_group/pop_size)**2 * (var_untreated/n_untreated + var_treated/n_treated)\n",
    "    return ATE_group, variance_group\n",
    "\n",
    "stratified_ATE(DF, DF.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41007383, -0.38821264, -0.39971652, ..., -0.40583505,\n",
       "       -0.42754707, -0.43093322])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logit(p):\n",
    "    return np.log(p/(1-p))\n",
    "\n",
    "def propensity_score(DF, covariates, scaler, convert_to_logit):\n",
    "    \n",
    "    \"\"\" Compute propensity score estimates: the probability (logistic regression) that an observation is treated or not conditioned on some covariates.\n",
    "\n",
    "        DF:                dataframe,\n",
    "        covariates:        list of strings for covariates variable in DF,\n",
    "        scaler:            sklearn.preprocessing function scaler for exemple,\n",
    "        convert_to_logit:  boolean for converting probabilities to logit when building the propensity score estimates based on a logistic regression\n",
    "    \"\"\"\n",
    "\n",
    "    if scaler != None:\n",
    "        pipe = Pipeline([('scaler', scaler),('logistic_classifier', LogisticRegression())])\n",
    "    else:\n",
    "        pipe = Pipeline([('logistic_classifier', LogisticRegression())])\n",
    "    pipe.fit(DF[covariates], DF.treatment)\n",
    "    predictions = pipe.predict_proba(DF[covariates])\n",
    "    if convert_to_logit:\n",
    "        predictions_logit = logit(predictions[:,1])\n",
    "        return predictions_logit\n",
    "    else: \n",
    "        return predictions[:,1]\n",
    "\n",
    "propensity_score(DF, covariates, MinMaxScaler(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF['propensity_score'] = propensity_score(DF, covariates, MinMaxScaler(), True)\n",
    "q = 5 # recommended\n",
    "DF['prop_score_quantile'] = pds.qcut(DF['propensity_score'], q, labels = False)\n",
    "\n",
    "# check the balance\n",
    "np.array([(DF[DF['prop_score_quantile']==value].treatment.value_counts() > DF.shape[0]/(q*3)).all() for value in range(q)]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43.83599521070258, 0.15905622636676375)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ATE(DF, strata): # covariates=None, scaler=None, convert_to_logit=None,\n",
    "    \n",
    "    \"\"\" Compute the Average Treatment Effect in DF according to the stratification method:\n",
    "        no stratification when strata is None, \n",
    "        stratified dataframe build based on the list of specific covariates when one is passed,\n",
    "        or propensity score stratification.\n",
    "        Propensity score estimates are built conditionaly on covariates passed using a logistic regression after transformation by scaler (when one is specified).\n",
    "        Estimated probabilities can be converted into logit (convert_to_logit parameter).\n",
    "        Quantiles are used to partition the data based on propensity score estimates.\n",
    "        'covariates', 'scaler', 'convert_to_logit', 'quantiles' are only needed for 'propensity stratification' method.\n",
    "\n",
    "        DF:                dataframe,\n",
    "        strata:            value in {None, [...], 'propensity stratification'},\n",
    "        covariates:        list of strings for covariates variable in DF,\n",
    "        scaler:            sklearn.preprocessing function scaler for exemple,\n",
    "        convert_to_logit:  boolean for converting probabilities to logit when building the propensity score estimates based on a logistic regression,\n",
    "        quantiles:         list of quantiles (>0) to consider to build strata based on propensity score\n",
    "    \"\"\"\n",
    "    \n",
    "    pop_size = DF.shape[0]\n",
    "    if strata == None: # no stratification\n",
    "        return stratified_ATE(DF, pop_size)\n",
    "    elif strata == 'propensity stratification': # propensity score stratification\n",
    "        assert ('propensity_score' in DF.columns)&('prop_score_quantile' in DF.columns), (\"For propensity score stratification you need first to add the propensity_score and prop_score_quantile columns into the dataframe.\")\n",
    "        ATE, variance = 0, 0\n",
    "        for q in DF['prop_score_quantile'].unique():\n",
    "            stratum_data = DF[DF['prop_score_quantile'] == q]\n",
    "            ATE_stratum, variance_stratum = stratified_ATE(stratum_data, pop_size)\n",
    "            ATE += ATE_stratum\n",
    "            variance += variance_stratum\n",
    "        return ATE, variance\n",
    "    else: # stratification based on the covariates passed\n",
    "        ATE, variance = 0, 0\n",
    "        for stratum in DF.groupby(strata):\n",
    "            stratum_id, stratum_data = stratum\n",
    "            ATE_stratum, variance_stratum = stratified_ATE(stratum_data, pop_size)\n",
    "            ATE += ATE_stratum\n",
    "            variance += variance_stratum\n",
    "        return ATE, variance\n",
    "\n",
    "ATE(DF, 'propensity stratification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43.855209924135366, 0.15908948881291174)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATE(DF, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_7/32t15g3d2h54d0ct6cssb9gh0000gn/T/ipykernel_2084/3199416953.py:34: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for stratum in DF.groupby(strata):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(43.85639628206826, 0.15913698174475693)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATE(DF, ['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([47.33719513914916,\n",
       "  46.39276952192214,\n",
       "  46.153054900522065,\n",
       "  45.27140935392173,\n",
       "  44.72825817031678,\n",
       "  15.600965590480033,\n",
       "  15.49195327496395,\n",
       "  15.309637357517015,\n",
       "  13.781570614273592,\n",
       "  13.781329335788602],\n",
       " [69.30381736813325,\n",
       "  65.3316786061727,\n",
       "  67.11109893024654,\n",
       "  64.5648768468791,\n",
       "  61.89730849861741,\n",
       "  13.821247094960613,\n",
       "  13.805832166752769,\n",
       "  13.432986717798697,\n",
       "  11.510034145134389,\n",
       "  11.402201028704862])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Estimate_Tethered_Stopping_Rule(A, B, identifiers, match, unmatch, covariates, scaler, convert_to_logit):\n",
    "\n",
    "    \"\"\" Compare records in A with records in B, computing all linking scores for records in A with records in B. \n",
    "        Return the indices of records in A with the best match index for record in B.\n",
    "\n",
    "        A: dataframe, \n",
    "        B: dataframe, \n",
    "        identifiers: dict: k = column name, v = method in {'large','strict','levenshtein','jaro-winkler',\n",
    "        match: array of probabilities of having same linking variables when being a match,\n",
    "        unmatch: array of probabilities of having same linking variables (at all, among the nA x nB pairs of record),\n",
    "        strata: .\n",
    "    \"\"\"\n",
    "    \n",
    "    correct_links = almost_exact_matches(A, B, identifiers)\n",
    "    matchings = linking_score(A, B, identifiers, match, unmatch)\n",
    "    from_A = A.iloc[correct_links['A'],:].drop('source', axis=1).reset_index(drop=True)\n",
    "    from_B = B.iloc[correct_links['B'],:]['Y'].reset_index(drop=True)\n",
    "    linked_records = pds.concat([from_A, from_B], axis = 1)\n",
    "    ATE_links, variance_links = ATE(linked_records, 'propensity stratification')\n",
    "    ATE_list = [ATE_links]\n",
    "    Var_list = [variance_links]\n",
    "    for score in np.sort(np.unique(matchings['scores']))[::-1][1:]:\n",
    "        new_matchings = matchings['A'][matchings['scores'] == score]\n",
    "        from_A = A.iloc[new_matchings,:].drop('source', axis=1).reset_index(drop=True)\n",
    "        from_B = B.iloc[matchings['B'][new_matchings],:]['Y'].reset_index(drop=True)\n",
    "        linked_records = pds.concat([linked_records, pds.concat([from_A,from_B], axis = 1)])\n",
    "        ATE_links, variance_links = ATE(linked_records, 'propensity stratification')\n",
    "        ATE_list.append(ATE_links)\n",
    "        Var_list.append(variance_links)\n",
    "    return ATE_list, Var_list\n",
    "\n",
    "A['propensity_score'] = propensity_score(A, covariates, MinMaxScaler(), True)\n",
    "q = 5 # recommended\n",
    "A['prop_score_quantile'] = pds.qcut(A['propensity_score'], q, labels = False)\n",
    "\n",
    "# check the balance\n",
    "np.array([(A[A['prop_score_quantile']==value].treatment.value_counts() > A.shape[0]/(q*3)).all() for value in range(q)]).all()\n",
    "\n",
    "Estimate_Tethered_Stopping_Rule(A, B, identifiers, match, unmatch, ['X1','X2','X3'], MinMaxScaler(), True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tester",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b95706f4894ee4355943f31879e0e3a76d825289e1bc7e0d16bc1dcbc4ba3b09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
