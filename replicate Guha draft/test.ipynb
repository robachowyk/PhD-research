{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import numpy as np\n",
    "import textdistance\n",
    "import timeit\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "from patsy import dmatrix\n",
    "import time\n",
    "import math\n",
    "import tqdm\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_DF = 'DF_N=4401_2023-01-16.csv'\n",
    "DF = pds.read_csv(os.path.join('..', 'datasets', name_DF), delimiter = ',')\n",
    "DF = DF[~DF.duplicated()] # delete duplicates\n",
    "DF = DF.dropna() # delete NaN values\n",
    "DF['was_assigned_female'] = DF['was_assigned_female'].astype('int32') # turn was_born_female into int type (once Nan values have been removed)\n",
    "\n",
    "identifiers = {'family_name':'jaro-winkler','was_assigned_female':'strict','country':'strict','birth_year':'large'}\n",
    "covariates = ['X1','X2','X3','X4','X5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GENERATES ASSOCIATION ##########           \n",
    "\n",
    "# generate covariates\n",
    "DF['X1'] = 2020 - DF['birth_year'] # age\n",
    "DF['X2'] = np.random.normal(loc = 2.5, scale = 1, size = DF.shape[0])\n",
    "DF['X3'] = np.random.normal(loc = 0, scale = 1, size = DF.shape[0])\n",
    "DF['X4'] = np.random.normal(loc = 1, scale = 1, size = DF.shape[0])\n",
    "DF['X5'] = np.random.normal(loc = 1, scale = 1, size = DF.shape[0])\n",
    "\n",
    "# generate treatment\n",
    "DF['treatment'] = np.random.binomial(n = 1, p = 1 / ( 1 + np.exp(0.1*DF.X1 -0.2*DF.X2 +0.3*DF.X3 -0.4*DF.X4 +0.5*DF.X5) )) # probability depending on covariates\n",
    "\n",
    "# generate outcome\n",
    "residual_errors = np.random.normal(size = DF.shape[0])\n",
    "a = 5.5\n",
    "b = 0.01\n",
    "c = 0.08\n",
    "d = 0.7\n",
    "\n",
    "ate = a * 2.5\n",
    "DF['Y'] = - 10 + a*DF['treatment']*DF['X2'] + b*np.exp(DF['X4']) + c*DF['X3']*DF['X1'] + d*DF['X5'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_records = DF.sample(n = 800)\n",
    "\n",
    "B = pds.concat([DF.sample(n = 1400), common_records]).drop(['Y'], axis = 1)\n",
    "B = B.reset_index(drop=True)\n",
    "\n",
    "A = pds.concat([DF.sample(n = 2000), common_records])[list(identifiers.keys())+['Y']]\n",
    "A = A.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_similarity(a,b):\n",
    "\n",
    "    \"\"\" Check that levenshtein similarity (in [0,1]) is above 0.95.\n",
    "        \n",
    "        a: string,\n",
    "        b: string \"\"\"\n",
    "\n",
    "    if 1 - textdistance.levenshtein(a, b)/max(len(a),len(b)) >= 0.95:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def jaro_winkler_similarity(a,b):\n",
    "\n",
    "    \"\"\" Check that jaro-winkler similarity (in [0,1]) is above 0.95.\n",
    "        \n",
    "        a: string,\n",
    "        b: string \"\"\"\n",
    "\n",
    "    if textdistance.jaro_winkler(a,b) >= 0.99:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def strict_equality(a,b):\n",
    "\n",
    "    \"\"\" Check that a and b values are equal.\n",
    "        \n",
    "        a: any value,\n",
    "        b: any value \"\"\"\n",
    "\n",
    "    return a==b\n",
    "\n",
    "def large_equality(a,b):\n",
    "\n",
    "    \"\"\" Check that years a and b expressed with four numbers are within the same decade.\n",
    "        \n",
    "        a: year,\n",
    "        b: year \"\"\"\n",
    "\n",
    "    return str(a)[:-1]==str(b)[:-1]\n",
    "\n",
    "def logit(p):\n",
    "    return np.log(p/(1-p))\n",
    "\n",
    "def minmaxscaler(X):\n",
    "    return (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "    \n",
    "def propensity_score(DF, covariates, scaler, convert_to_logit):\n",
    "    \n",
    "    \"\"\" Compute propensity score estimates: the probability (logistic regression) that an observation is treated or not conditioned on some covariates.\n",
    "        These estimates are built conditionaly on covariates passed using a logit after transformation by scaler (when one is specified).\n",
    "        Estimated probabilities can be converted into logit (convert_to_logit parameter).\n",
    "\n",
    "        DF:                dataframe,\n",
    "        covariates:        list of strings for covariates variable in DF,\n",
    "        scaler:            sklearn.preprocessing function scaler for exemple,\n",
    "        convert_to_logit:  boolean for converting probabilities to logit when building the propensity score estimates based on a logistic regression\n",
    "    \"\"\"\n",
    "    exog = covariates.copy()\n",
    "    if scaler != None:\n",
    "        DF[exog] = scaler(DF[exog])\n",
    "    if 'intercept' not in DF.columns:\n",
    "        DF['intercept'] = 1\n",
    "    exog.append('intercept')\n",
    "    model = sm.Logit(DF.treatment, DF[exog]).fit(disp=0)\n",
    "    predictions = model.predict(DF[exog])\n",
    "    if convert_to_logit:\n",
    "        return logit(predictions)\n",
    "    else: \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>family_name_x</th>\n",
       "      <th>country_x</th>\n",
       "      <th>birth_year_x</th>\n",
       "      <th>was_assigned_female_x</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>treatment</th>\n",
       "      <th>family_name_y</th>\n",
       "      <th>was_assigned_female_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>birth_year_y</th>\n",
       "      <th>Y</th>\n",
       "      <th>source_index_B</th>\n",
       "      <th>source_index_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leonardo</td>\n",
       "      <td>Pantoja Aguilera</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4.692437</td>\n",
       "      <td>-0.072021</td>\n",
       "      <td>2.007894</td>\n",
       "      <td>1.268998</td>\n",
       "      <td>0</td>\n",
       "      <td>Ellerington</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>1982</td>\n",
       "      <td>-12.140245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leonardo</td>\n",
       "      <td>Pantoja Aguilera</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4.692437</td>\n",
       "      <td>-0.072021</td>\n",
       "      <td>2.007894</td>\n",
       "      <td>1.268998</td>\n",
       "      <td>0</td>\n",
       "      <td>Shelton</td>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>1957</td>\n",
       "      <td>-8.198515</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leonardo</td>\n",
       "      <td>Pantoja Aguilera</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4.692437</td>\n",
       "      <td>-0.072021</td>\n",
       "      <td>2.007894</td>\n",
       "      <td>1.268998</td>\n",
       "      <td>0</td>\n",
       "      <td>Dorofeeva</td>\n",
       "      <td>1</td>\n",
       "      <td>RU</td>\n",
       "      <td>1955</td>\n",
       "      <td>-1.731686</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonardo</td>\n",
       "      <td>Pantoja Aguilera</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4.692437</td>\n",
       "      <td>-0.072021</td>\n",
       "      <td>2.007894</td>\n",
       "      <td>1.268998</td>\n",
       "      <td>0</td>\n",
       "      <td>Wagner</td>\n",
       "      <td>0</td>\n",
       "      <td>NL</td>\n",
       "      <td>1999</td>\n",
       "      <td>-10.772816</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leonardo</td>\n",
       "      <td>Pantoja Aguilera</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4.692437</td>\n",
       "      <td>-0.072021</td>\n",
       "      <td>2.007894</td>\n",
       "      <td>1.268998</td>\n",
       "      <td>0</td>\n",
       "      <td>Wardzała</td>\n",
       "      <td>0</td>\n",
       "      <td>PL</td>\n",
       "      <td>1970</td>\n",
       "      <td>-5.692543</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159995</th>\n",
       "      <td>Mirjana</td>\n",
       "      <td>Stankovic</td>\n",
       "      <td>RS</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>-0.163625</td>\n",
       "      <td>-0.676903</td>\n",
       "      <td>0.932684</td>\n",
       "      <td>1</td>\n",
       "      <td>Mulack</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>1995</td>\n",
       "      <td>-12.525451</td>\n",
       "      <td>2199</td>\n",
       "      <td>2795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159996</th>\n",
       "      <td>Mirjana</td>\n",
       "      <td>Stankovic</td>\n",
       "      <td>RS</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>-0.163625</td>\n",
       "      <td>-0.676903</td>\n",
       "      <td>0.932684</td>\n",
       "      <td>1</td>\n",
       "      <td>Müller</td>\n",
       "      <td>0</td>\n",
       "      <td>AT</td>\n",
       "      <td>1972</td>\n",
       "      <td>-7.666611</td>\n",
       "      <td>2199</td>\n",
       "      <td>2796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159997</th>\n",
       "      <td>Mirjana</td>\n",
       "      <td>Stankovic</td>\n",
       "      <td>RS</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>-0.163625</td>\n",
       "      <td>-0.676903</td>\n",
       "      <td>0.932684</td>\n",
       "      <td>1</td>\n",
       "      <td>Di Riccio</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>2013</td>\n",
       "      <td>-10.106473</td>\n",
       "      <td>2199</td>\n",
       "      <td>2797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159998</th>\n",
       "      <td>Mirjana</td>\n",
       "      <td>Stankovic</td>\n",
       "      <td>RS</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>-0.163625</td>\n",
       "      <td>-0.676903</td>\n",
       "      <td>0.932684</td>\n",
       "      <td>1</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>1</td>\n",
       "      <td>ES</td>\n",
       "      <td>1954</td>\n",
       "      <td>-13.690015</td>\n",
       "      <td>2199</td>\n",
       "      <td>2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159999</th>\n",
       "      <td>Mirjana</td>\n",
       "      <td>Stankovic</td>\n",
       "      <td>RS</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>-0.163625</td>\n",
       "      <td>-0.676903</td>\n",
       "      <td>0.932684</td>\n",
       "      <td>1</td>\n",
       "      <td>Stankovic</td>\n",
       "      <td>1</td>\n",
       "      <td>RS</td>\n",
       "      <td>1998</td>\n",
       "      <td>-9.448911</td>\n",
       "      <td>2199</td>\n",
       "      <td>2799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6160000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name     family_name_x country_x  birth_year_x  \\\n",
       "0        Leonardo  Pantoja Aguilera        ES          1981   \n",
       "1        Leonardo  Pantoja Aguilera        ES          1981   \n",
       "2        Leonardo  Pantoja Aguilera        ES          1981   \n",
       "3        Leonardo  Pantoja Aguilera        ES          1981   \n",
       "4        Leonardo  Pantoja Aguilera        ES          1981   \n",
       "...           ...               ...       ...           ...   \n",
       "6159995   Mirjana         Stankovic        RS          1998   \n",
       "6159996   Mirjana         Stankovic        RS          1998   \n",
       "6159997   Mirjana         Stankovic        RS          1998   \n",
       "6159998   Mirjana         Stankovic        RS          1998   \n",
       "6159999   Mirjana         Stankovic        RS          1998   \n",
       "\n",
       "         was_assigned_female_x  X1        X2        X3        X4        X5  \\\n",
       "0                            0  39  4.692437 -0.072021  2.007894  1.268998   \n",
       "1                            0  39  4.692437 -0.072021  2.007894  1.268998   \n",
       "2                            0  39  4.692437 -0.072021  2.007894  1.268998   \n",
       "3                            0  39  4.692437 -0.072021  2.007894  1.268998   \n",
       "4                            0  39  4.692437 -0.072021  2.007894  1.268998   \n",
       "...                        ...  ..       ...       ...       ...       ...   \n",
       "6159995                      1  22  0.032929 -0.163625 -0.676903  0.932684   \n",
       "6159996                      1  22  0.032929 -0.163625 -0.676903  0.932684   \n",
       "6159997                      1  22  0.032929 -0.163625 -0.676903  0.932684   \n",
       "6159998                      1  22  0.032929 -0.163625 -0.676903  0.932684   \n",
       "6159999                      1  22  0.032929 -0.163625 -0.676903  0.932684   \n",
       "\n",
       "         treatment family_name_y  was_assigned_female_y country_y  \\\n",
       "0                0   Ellerington                      0        GB   \n",
       "1                0       Shelton                      1        GB   \n",
       "2                0     Dorofeeva                      1        RU   \n",
       "3                0        Wagner                      0        NL   \n",
       "4                0      Wardzała                      0        PL   \n",
       "...            ...           ...                    ...       ...   \n",
       "6159995          1        Mulack                      0        DE   \n",
       "6159996          1        Müller                      0        AT   \n",
       "6159997          1     Di Riccio                      0        IT   \n",
       "6159998          1       Sanchez                      1        ES   \n",
       "6159999          1     Stankovic                      1        RS   \n",
       "\n",
       "         birth_year_y          Y  source_index_B  source_index_A  \n",
       "0                1982 -12.140245               0               0  \n",
       "1                1957  -8.198515               0               1  \n",
       "2                1955  -1.731686               0               2  \n",
       "3                1999 -10.772816               0               3  \n",
       "4                1970  -5.692543               0               4  \n",
       "...               ...        ...             ...             ...  \n",
       "6159995          1995 -12.525451            2199            2795  \n",
       "6159996          1972  -7.666611            2199            2796  \n",
       "6159997          2013 -10.106473            2199            2797  \n",
       "6159998          1954 -13.690015            2199            2798  \n",
       "6159999          1998  -9.448911            2199            2799  \n",
       "\n",
       "[6160000 rows x 18 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AB = B.merge(A, how='cross')\n",
    "AB[\"source_index_B\"] = np.repeat(B.index, A.shape[0])\n",
    "AB[\"source_index_A\"] = np.tile(A.index, B.shape[0])\n",
    "AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>family_name_x</th>\n",
       "      <th>country_x</th>\n",
       "      <th>birth_year_x</th>\n",
       "      <th>was_assigned_female_x</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>...</th>\n",
       "      <th>Y</th>\n",
       "      <th>source_index_B</th>\n",
       "      <th>source_index_A</th>\n",
       "      <th>family_name_comparison</th>\n",
       "      <th>was_assigned_female_comparison</th>\n",
       "      <th>country_comparison</th>\n",
       "      <th>birth_year_comparison</th>\n",
       "      <th>linking_score</th>\n",
       "      <th>intercept</th>\n",
       "      <th>propensity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leonardo</td>\n",
       "      <td>Pantoja Aguilera</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4.692437</td>\n",
       "      <td>-0.072021</td>\n",
       "      <td>2.007894</td>\n",
       "      <td>1.268998</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.140245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.865795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leonardo</td>\n",
       "      <td>Pantoja Aguilera</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4.692437</td>\n",
       "      <td>-0.072021</td>\n",
       "      <td>2.007894</td>\n",
       "      <td>1.268998</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.198515</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.883013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leonardo</td>\n",
       "      <td>Pantoja Aguilera</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4.692437</td>\n",
       "      <td>-0.072021</td>\n",
       "      <td>2.007894</td>\n",
       "      <td>1.268998</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.731686</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.883013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonardo</td>\n",
       "      <td>Pantoja Aguilera</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4.692437</td>\n",
       "      <td>-0.072021</td>\n",
       "      <td>2.007894</td>\n",
       "      <td>1.268998</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.772816</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.640484</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leonardo</td>\n",
       "      <td>Pantoja Aguilera</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4.692437</td>\n",
       "      <td>-0.072021</td>\n",
       "      <td>2.007894</td>\n",
       "      <td>1.268998</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.692543</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.640484</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159995</th>\n",
       "      <td>Mirjana</td>\n",
       "      <td>Stankovic</td>\n",
       "      <td>RS</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>-0.163625</td>\n",
       "      <td>-0.676903</td>\n",
       "      <td>0.932684</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.525451</td>\n",
       "      <td>2199</td>\n",
       "      <td>2795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.108324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159996</th>\n",
       "      <td>Mirjana</td>\n",
       "      <td>Stankovic</td>\n",
       "      <td>RS</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>-0.163625</td>\n",
       "      <td>-0.676903</td>\n",
       "      <td>0.932684</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.666611</td>\n",
       "      <td>2199</td>\n",
       "      <td>2796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.883013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159997</th>\n",
       "      <td>Mirjana</td>\n",
       "      <td>Stankovic</td>\n",
       "      <td>RS</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>-0.163625</td>\n",
       "      <td>-0.676903</td>\n",
       "      <td>0.932684</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.106473</td>\n",
       "      <td>2199</td>\n",
       "      <td>2797</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.883013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159998</th>\n",
       "      <td>Mirjana</td>\n",
       "      <td>Stankovic</td>\n",
       "      <td>RS</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>-0.163625</td>\n",
       "      <td>-0.676903</td>\n",
       "      <td>0.932684</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.690015</td>\n",
       "      <td>2199</td>\n",
       "      <td>2798</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.640484</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159999</th>\n",
       "      <td>Mirjana</td>\n",
       "      <td>Stankovic</td>\n",
       "      <td>RS</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>-0.163625</td>\n",
       "      <td>-0.676903</td>\n",
       "      <td>0.932684</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.448911</td>\n",
       "      <td>2199</td>\n",
       "      <td>2799</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.986292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6160000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name     family_name_x country_x  birth_year_x  \\\n",
       "0        Leonardo  Pantoja Aguilera        ES          1981   \n",
       "1        Leonardo  Pantoja Aguilera        ES          1981   \n",
       "2        Leonardo  Pantoja Aguilera        ES          1981   \n",
       "3        Leonardo  Pantoja Aguilera        ES          1981   \n",
       "4        Leonardo  Pantoja Aguilera        ES          1981   \n",
       "...           ...               ...       ...           ...   \n",
       "6159995   Mirjana         Stankovic        RS          1998   \n",
       "6159996   Mirjana         Stankovic        RS          1998   \n",
       "6159997   Mirjana         Stankovic        RS          1998   \n",
       "6159998   Mirjana         Stankovic        RS          1998   \n",
       "6159999   Mirjana         Stankovic        RS          1998   \n",
       "\n",
       "         was_assigned_female_x  X1        X2        X3        X4        X5  \\\n",
       "0                            0  39  4.692437 -0.072021  2.007894  1.268998   \n",
       "1                            0  39  4.692437 -0.072021  2.007894  1.268998   \n",
       "2                            0  39  4.692437 -0.072021  2.007894  1.268998   \n",
       "3                            0  39  4.692437 -0.072021  2.007894  1.268998   \n",
       "4                            0  39  4.692437 -0.072021  2.007894  1.268998   \n",
       "...                        ...  ..       ...       ...       ...       ...   \n",
       "6159995                      1  22  0.032929 -0.163625 -0.676903  0.932684   \n",
       "6159996                      1  22  0.032929 -0.163625 -0.676903  0.932684   \n",
       "6159997                      1  22  0.032929 -0.163625 -0.676903  0.932684   \n",
       "6159998                      1  22  0.032929 -0.163625 -0.676903  0.932684   \n",
       "6159999                      1  22  0.032929 -0.163625 -0.676903  0.932684   \n",
       "\n",
       "         ...          Y source_index_B  source_index_A family_name_comparison  \\\n",
       "0        ... -12.140245              0               0                      0   \n",
       "1        ...  -8.198515              0               1                      0   \n",
       "2        ...  -1.731686              0               2                      0   \n",
       "3        ... -10.772816              0               3                      0   \n",
       "4        ...  -5.692543              0               4                      0   \n",
       "...      ...        ...            ...             ...                    ...   \n",
       "6159995  ... -12.525451           2199            2795                      0   \n",
       "6159996  ...  -7.666611           2199            2796                      0   \n",
       "6159997  ... -10.106473           2199            2797                      0   \n",
       "6159998  ... -13.690015           2199            2798                      0   \n",
       "6159999  ...  -9.448911           2199            2799                      1   \n",
       "\n",
       "         was_assigned_female_comparison  country_comparison  \\\n",
       "0                                     1                   0   \n",
       "1                                     0                   0   \n",
       "2                                     0                   0   \n",
       "3                                     1                   0   \n",
       "4                                     1                   0   \n",
       "...                                 ...                 ...   \n",
       "6159995                               0                   0   \n",
       "6159996                               0                   0   \n",
       "6159997                               0                   0   \n",
       "6159998                               1                   0   \n",
       "6159999                               1                   1   \n",
       "\n",
       "         birth_year_comparison  linking_score  intercept  propensity_score  \n",
       "0                            1      -4.865795          1          0.077754  \n",
       "1                            0     -15.883013          1          0.077754  \n",
       "2                            0     -15.883013          1          0.077754  \n",
       "3                            0     -11.640484          1          0.077754  \n",
       "4                            0     -11.640484          1          0.077754  \n",
       "...                        ...            ...        ...               ...  \n",
       "6159995                      1      -9.108324          1          0.039322  \n",
       "6159996                      0     -15.883013          1          0.039322  \n",
       "6159997                      0     -15.883013          1          0.039322  \n",
       "6159998                      0     -11.640484          1          0.039322  \n",
       "6159999                      1      17.986292          1          0.039322  \n",
       "\n",
       "[6160000 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods = {'jaro-winkler':jaro_winkler_similarity, 'levenshtein':levenshtein_similarity, 'strict':strict_equality, 'large':large_equality}\n",
    "\n",
    "for linking_var in identifiers.keys():\n",
    "    method = methods[identifiers[linking_var]]\n",
    "    df = AB.filter(regex=linking_var)\n",
    "    AB[linking_var+\"_comparison\"] = np.array([method(a, b) for a,b in zip(df.iloc[:,0], df.iloc[:,1])]).astype(int).reshape(-1,1)\n",
    "\n",
    "comparison_vectors_only = AB.filter(regex=\"comparison\")\n",
    "\n",
    "unmatch = np.array(comparison_vectors_only.sum(axis=0) / len(comparison_vectors_only)) # probability of having same linking var (at all)\n",
    "match = np.repeat(0.95, len(identifiers.keys())) # probability of having same linking var when being matches\n",
    "\n",
    "AB[\"linking_score\"] = (np.multiply(comparison_vectors_only, np.log2(match/unmatch)) + np.multiply(1-comparison_vectors_only, np.log2((1-match)/(1-unmatch)))).sum(axis=1)\n",
    "AB['propensity_score'] = propensity_score(AB, covariates, None, False)\n",
    "AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_name_comparison</th>\n",
       "      <th>was_assigned_female_comparison</th>\n",
       "      <th>country_comparison</th>\n",
       "      <th>birth_year_comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6160000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         family_name_comparison  was_assigned_female_comparison  \\\n",
       "0                             0                               1   \n",
       "1                             0                               0   \n",
       "2                             0                               0   \n",
       "3                             0                               1   \n",
       "4                             0                               1   \n",
       "...                         ...                             ...   \n",
       "6159995                       0                               0   \n",
       "6159996                       0                               0   \n",
       "6159997                       0                               0   \n",
       "6159998                       0                               1   \n",
       "6159999                       1                               1   \n",
       "\n",
       "         country_comparison  birth_year_comparison  \n",
       "0                         0                      1  \n",
       "1                         0                      0  \n",
       "2                         0                      0  \n",
       "3                         0                      0  \n",
       "4                         0                      0  \n",
       "...                     ...                    ...  \n",
       "6159995                   0                      1  \n",
       "6159996                   0                      0  \n",
       "6159997                   0                      0  \n",
       "6159998                   0                      0  \n",
       "6159999                   1                      1  \n",
       "\n",
       "[6160000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_vectors_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>family_name_x</th>\n",
       "      <th>country_x</th>\n",
       "      <th>birth_year_x</th>\n",
       "      <th>was_assigned_female_x</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>...</th>\n",
       "      <th>Y</th>\n",
       "      <th>source_index_B</th>\n",
       "      <th>source_index_A</th>\n",
       "      <th>family_name_comparison</th>\n",
       "      <th>was_assigned_female_comparison</th>\n",
       "      <th>country_comparison</th>\n",
       "      <th>birth_year_comparison</th>\n",
       "      <th>linking_score</th>\n",
       "      <th>intercept</th>\n",
       "      <th>propensity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15965</th>\n",
       "      <td>Pablo</td>\n",
       "      <td>Quejigo Sanchez-Guijaldo</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.872724</td>\n",
       "      <td>-0.590046</td>\n",
       "      <td>1.602619</td>\n",
       "      <td>0.645198</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.339644</td>\n",
       "      <td>5</td>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.986292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16874</th>\n",
       "      <td>Tamás</td>\n",
       "      <td>Stein</td>\n",
       "      <td>HU</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2.882410</td>\n",
       "      <td>-0.094059</td>\n",
       "      <td>0.916818</td>\n",
       "      <td>1.888200</td>\n",
       "      <td>...</td>\n",
       "      <td>7.124761</td>\n",
       "      <td>6</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.986292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32105</th>\n",
       "      <td>Кристина</td>\n",
       "      <td>Иванова</td>\n",
       "      <td>RU</td>\n",
       "      <td>1955</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1.327448</td>\n",
       "      <td>-0.209474</td>\n",
       "      <td>2.028906</td>\n",
       "      <td>1.065008</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.267703</td>\n",
       "      <td>11</td>\n",
       "      <td>1305</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.986292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39927</th>\n",
       "      <td>Marc</td>\n",
       "      <td>Helmstedt</td>\n",
       "      <td>DE</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.438209</td>\n",
       "      <td>-0.871638</td>\n",
       "      <td>0.034779</td>\n",
       "      <td>0.711052</td>\n",
       "      <td>...</td>\n",
       "      <td>3.569585</td>\n",
       "      <td>14</td>\n",
       "      <td>727</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.986292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46535</th>\n",
       "      <td>Joël</td>\n",
       "      <td>Masse</td>\n",
       "      <td>FR</td>\n",
       "      <td>1978</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.579975</td>\n",
       "      <td>-0.799582</td>\n",
       "      <td>0.061675</td>\n",
       "      <td>0.650069</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.220911</td>\n",
       "      <td>16</td>\n",
       "      <td>1735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.986292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6137591</th>\n",
       "      <td>Света</td>\n",
       "      <td>Федорова</td>\n",
       "      <td>RU</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.640018</td>\n",
       "      <td>0.026614</td>\n",
       "      <td>2.093515</td>\n",
       "      <td>1.117895</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.132082</td>\n",
       "      <td>2191</td>\n",
       "      <td>2791</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.986292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140392</th>\n",
       "      <td>Eduart</td>\n",
       "      <td>Muçaj</td>\n",
       "      <td>AL</td>\n",
       "      <td>1948</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>3.018400</td>\n",
       "      <td>-0.133854</td>\n",
       "      <td>1.505993</td>\n",
       "      <td>1.667673</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.558542</td>\n",
       "      <td>2192</td>\n",
       "      <td>2792</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.986292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143193</th>\n",
       "      <td>Magnus</td>\n",
       "      <td>Wessén</td>\n",
       "      <td>SE</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.218967</td>\n",
       "      <td>0.739057</td>\n",
       "      <td>-1.074466</td>\n",
       "      <td>0.303198</td>\n",
       "      <td>...</td>\n",
       "      <td>7.979095</td>\n",
       "      <td>2193</td>\n",
       "      <td>2793</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.986292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148795</th>\n",
       "      <td>Steffen</td>\n",
       "      <td>Mulack</td>\n",
       "      <td>DE</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2.100075</td>\n",
       "      <td>-1.274984</td>\n",
       "      <td>1.190283</td>\n",
       "      <td>-0.011946</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.525451</td>\n",
       "      <td>2195</td>\n",
       "      <td>2795</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.986292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154397</th>\n",
       "      <td>Franco</td>\n",
       "      <td>Di Riccio</td>\n",
       "      <td>IT</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.781704</td>\n",
       "      <td>-1.670856</td>\n",
       "      <td>-0.690744</td>\n",
       "      <td>1.177420</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.106473</td>\n",
       "      <td>2197</td>\n",
       "      <td>2797</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.986292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.445799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>833 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name             family_name_x country_x  birth_year_x  \\\n",
       "15965       Pablo  Quejigo Sanchez-Guijaldo        ES          1981   \n",
       "16874       Tamás                     Stein        HU          2010   \n",
       "32105    Кристина                   Иванова        RU          1955   \n",
       "39927        Marc                 Helmstedt        DE          2015   \n",
       "46535        Joël                     Masse        FR          1978   \n",
       "...           ...                       ...       ...           ...   \n",
       "6137591     Света                  Федорова        RU          2018   \n",
       "6140392    Eduart                     Muçaj        AL          1948   \n",
       "6143193    Magnus                    Wessén        SE          2019   \n",
       "6148795   Steffen                    Mulack        DE          1995   \n",
       "6154397    Franco                 Di Riccio        IT          2013   \n",
       "\n",
       "         was_assigned_female_x  X1        X2        X3        X4        X5  \\\n",
       "15965                        0  39  1.872724 -0.590046  1.602619  0.645198   \n",
       "16874                        0  10  2.882410 -0.094059  0.916818  1.888200   \n",
       "32105                        1  65  1.327448 -0.209474  2.028906  1.065008   \n",
       "39927                        0   5  2.438209 -0.871638  0.034779  0.711052   \n",
       "46535                        0  42  1.579975 -0.799582  0.061675  0.650069   \n",
       "...                        ...  ..       ...       ...       ...       ...   \n",
       "6137591                      1   2  1.640018  0.026614  2.093515  1.117895   \n",
       "6140392                      0  72  3.018400 -0.133854  1.505993  1.667673   \n",
       "6143193                      0   1  3.218967  0.739057 -1.074466  0.303198   \n",
       "6148795                      0  25  2.100075 -1.274984  1.190283 -0.011946   \n",
       "6154397                      0   7  3.781704 -1.670856 -0.690744  1.177420   \n",
       "\n",
       "         ...          Y source_index_B  source_index_A family_name_comparison  \\\n",
       "15965    ... -11.339644              5            1965                      1   \n",
       "16874    ...   7.124761              6              74                      1   \n",
       "32105    ... -10.267703             11            1305                      1   \n",
       "39927    ...   3.569585             14             727                      1   \n",
       "46535    ... -12.220911             16            1735                      1   \n",
       "...      ...        ...            ...             ...                    ...   \n",
       "6137591  ...  -9.132082           2191            2791                      1   \n",
       "6140392  ...  -9.558542           2192            2792                      1   \n",
       "6143193  ...   7.979095           2193            2793                      1   \n",
       "6148795  ... -12.525451           2195            2795                      1   \n",
       "6154397  ... -10.106473           2197            2797                      1   \n",
       "\n",
       "         was_assigned_female_comparison  country_comparison  \\\n",
       "15965                                 1                   1   \n",
       "16874                                 1                   1   \n",
       "32105                                 1                   1   \n",
       "39927                                 1                   1   \n",
       "46535                                 1                   1   \n",
       "...                                 ...                 ...   \n",
       "6137591                               1                   1   \n",
       "6140392                               1                   1   \n",
       "6143193                               1                   1   \n",
       "6148795                               1                   1   \n",
       "6154397                               1                   1   \n",
       "\n",
       "         birth_year_comparison  linking_score  intercept  propensity_score  \n",
       "15965                        1      17.986292          1          0.041952  \n",
       "16874                        1      17.986292          1          0.300246  \n",
       "32105                        1      17.986292          1          0.002500  \n",
       "39927                        1      17.986292          1          0.458744  \n",
       "46535                        1      17.986292          1          0.016155  \n",
       "...                        ...            ...        ...               ...  \n",
       "6137591                      1      17.986292          1          0.583117  \n",
       "6140392                      1      17.986292          1          0.001301  \n",
       "6143193                      1      17.986292          1          0.433603  \n",
       "6148795                      1      17.986292          1          0.201209  \n",
       "6154397                      1      17.986292          1          0.445799  \n",
       "\n",
       "[833 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_good_comparisons = AB[comparison_vectors_only.all(axis=1)]\n",
    "\n",
    "# remove duplicata: \n",
    "where_good_comparisons = where_good_comparisons[ (~where_good_comparisons.source_index_A.duplicated(keep=False)) & (~where_good_comparisons.source_index_B.duplicated(keep=False)) ]\n",
    "where_good_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linked_records\n",
    "# create z0\n",
    "# look at true linkage\n",
    "\n",
    "idx_A = where_good_comparisons.source_index_A\n",
    "idx_B = where_good_comparisons.source_index_B\n",
    "\n",
    "from_A = A.iloc[idx_A,:].reset_index(drop=True)\n",
    "from_B = B.iloc[idx_B,:].reset_index(drop=True)\n",
    "\n",
    "linked_records = pds.concat([from_B, from_A.Y], axis=1)\n",
    "linked_records['propensity_score'] = propensity_score(linked_records, covariates, None, False)\n",
    "\n",
    "z0 = -np.ones(B.shape[0])\n",
    "z0[idx_B] = idx_A\n",
    "\n",
    "true_linkage_z = -np.ones(B.shape[0])\n",
    "true_linkage_z[B.iloc[-800:,:].index] = A.iloc[-800:,:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.000e+00, -1.000e+00, -1.000e+00, ...,  2.797e+03, -1.000e+00,\n",
       "       -1.000e+00])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.000e+00, -1.000e+00, -1.000e+00, ...,  2.797e+03,  2.798e+03,\n",
       "        2.799e+03])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_linkage_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5068181818181818"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(z0==true_linkage_z).sum()/len(z0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISATION\n",
    "\n",
    "z_k = [z0.copy()]\n",
    "linked_records_k = [linked_records.copy()]\n",
    "\n",
    "def update_linkage_param(cartesian_product_AB, previous_z):\n",
    "\n",
    "    idx_A = previous_z[previous_z>=0]\n",
    "    idx_B = np.nonzero(previous_z>=0)[0]\n",
    "    links = pds.MultiIndex.from_tuples(zip(idx_A,idx_B))\n",
    "    pairs = pds.MultiIndex.from_frame(cartesian_product_AB[[\"source_index_A\", \"source_index_B\"]])\n",
    "\n",
    "    data_match = cartesian_product_AB[pairs.isin(links)]\n",
    "    comparisons_match = data_match.filter(regex=\"comparison\")\n",
    "    new_theta_m = scipy.stats.beta.rvs(comparisons_match.sum(axis=0) + 1, (1-comparisons_match).sum(axis=0) + 1)\n",
    "\n",
    "    data_unmatch = cartesian_product_AB[(~pairs.isin(links)) & (~cartesian_product_AB.source_index_B.duplicated()) & (~cartesian_product_AB.source_index_A.duplicated())]\n",
    "    # REMARK: we also filtered on duplicata, otherwise data_unmatch is considering too many data and probabilities are too small\n",
    "    \n",
    "    comparisons_unmatch = data_unmatch.filter(regex=\"comparison\")\n",
    "    new_theta_u = scipy.stats.beta.rvs(comparisons_unmatch.sum(axis=0) + 1, (1-comparisons_unmatch).sum(axis=0) + 1)\n",
    "\n",
    "    return new_theta_m, new_theta_u\n",
    "\n",
    "theta_m_k = [match.copy()]\n",
    "theta_u_k = [unmatch.copy()]\n",
    "\n",
    "# build thetas:\n",
    "new_theta_m, new_theta_u = update_linkage_param(AB, z_k[-1])\n",
    "theta_m_k.append(new_theta_m)\n",
    "theta_u_k.append(new_theta_u)\n",
    "\n",
    "def update_unmatched_outcome_param(file_A, previous_z, previous_mu2, previous_sigma2_square, previous_a_sigma2, previous_b_sigma2):\n",
    "\n",
    "    idx_A = previous_z[previous_z>=0]\n",
    "\n",
    "    n_AB = (previous_z>=0).sum()\n",
    "    \n",
    "    non_linked_outcomes = file_A.iloc[~file_A.index.isin(idx_A),:].Y\n",
    "\n",
    "    new_sigma2_square = scipy.stats.invgauss.rvs(previous_a_sigma2 + (file_A.shape[0]-n_AB)/2, previous_b_sigma2 + ((non_linked_outcomes - previous_mu2)**2 / 2).sum())\n",
    "    sigma_mu_2_square = 1 / ((file_A.shape[0] -  n_AB)/previous_sigma2_square + 1)\n",
    "    m_mu_2 = sigma_mu_2_square * (non_linked_outcomes).sum() / previous_sigma2_square\n",
    "    \n",
    "    new_mu2 = scipy.stats.norm.rvs(m_mu_2, np.sqrt(sigma_mu_2_square))\n",
    "\n",
    "    return new_mu2, new_sigma2_square\n",
    "\n",
    "a_sigma2_k = [1]\n",
    "b_sigma2_k = [1]\n",
    "\n",
    "mu2_k = [scipy.stats.norm.rvs(0,1)]\n",
    "sigma2_square_k = [scipy.stats.invgauss.rvs(a_sigma2_k[-1],b_sigma2_k[-1])]\n",
    "\n",
    "new_mu2, new_sigma2_square = update_unmatched_outcome_param(A, z_k[-1], mu2_k[-1], sigma2_square_k[-1], a_sigma2_k[-1], b_sigma2_k[-1])\n",
    "mu2_k.append(new_mu2)\n",
    "sigma2_square_k.append(new_sigma2_square)\n",
    "\n",
    "def update_matched_outcome_param(cartesian_product_AB, previous_z, previous_linked_records, previous_beta0, previsou_beta1, previous_alpha, previous_sigma_square, previous_a_sigma, previous_b_sigma):\n",
    "\n",
    "    idx_A = previous_z[previous_z>=0]\n",
    "    idx_B = np.nonzero(previous_z>=0)[0]\n",
    "    links = pds.MultiIndex.from_tuples(zip(idx_A,idx_B))\n",
    "    pairs = pds.MultiIndex.from_frame(cartesian_product_AB[[\"source_index_A\", \"source_index_B\"]])\n",
    "\n",
    "    tilde_y = previous_linked_records.Y\n",
    "    tilde_K = np.array([previous_linked_records.intercept, previous_linked_records.propensity_score, previous_linked_records.treatment]).T\n",
    "\n",
    "    sigma_matrix = np.linalg.inv( tilde_K.T @ tilde_K / previous_sigma_square + np.eye(tilde_K.shape[1]) )\n",
    "    tilde_K.T @ tilde_y\n",
    "    mu_vector = sigma_matrix @ tilde_K.T @ tilde_y / previous_sigma_square\n",
    "    new_beta0, new_beta1, new_alpha = scipy.stats.multivariate_normal.rvs(mu_vector, sigma_matrix)\n",
    "\n",
    "    n_AB = (previous_z>=0).sum()\n",
    "    new_sigma_square = scipy.stats.invgauss.rvs(previous_a_sigma + n_AB/2, np.linalg.norm(tilde_y - tilde_K @ np.array([previous_beta0, previsou_beta1, previous_alpha]))**2 / 2 + previous_b_sigma)\n",
    "    \n",
    "    return new_beta0, new_beta1, new_alpha, new_sigma_square\n",
    "\n",
    "a_sigma_k = [1]\n",
    "b_sigma_k = [1]\n",
    "\n",
    "beta0_k = [scipy.stats.norm.rvs(0,1)]\n",
    "beta1_k = [scipy.stats.norm.rvs(0,1)]\n",
    "alpha_k = [scipy.stats.norm.rvs(0,1)]\n",
    "sigma_square_k = [scipy.stats.invgauss.rvs(a_sigma_k[-1],b_sigma_k[-1])]\n",
    "\n",
    "new_beta0, new_beta1, new_alpha, new_sigma_square = update_matched_outcome_param(AB, z_k[-1], linked_records_k[-1], beta0_k[-1], beta1_k[-1], alpha_k[-1], sigma_square_k[-1], a_sigma_k[-1], b_sigma_k[-1])\n",
    "beta0_k.append(new_beta0)\n",
    "beta1_k.append(new_beta1)\n",
    "alpha_k.append(new_alpha)\n",
    "sigma_square_k.append(new_sigma_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, 2382, -1, 2691, 1965, 74, -1, -1, -1, 977, 1305, -1, -1, 727, 1953, 2205, 956, -1, -1, -1, -1, -1, -1, 793, 1016, -1, 1363, -1, 342, -1, -1, 1384, -1, 2633, 2538, -1, 1283, 2243, 429, -1, -1, -1, 2297, 200, -1, -1, 1566, 1715, -1, 332, 2608, 331, -1, 804, -1, 872, -1, -1, 881, -1, 1782, 2120, -1, 2477, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 566, 471, 71, -1, 565, -1, 1082, -1, -1, 2039, 2059, -1, 469, 1249, -1, 1485, 1531, -1, 1187, 2730, 639, -1, 135, -1, 1525, 1141, 2599, 1178, 2299, -1, -1, -1, 2757, 1579, -1, -1, 781, -1, -1, 147, 2181, 601, 676, -1, -1, -1, 2275, 747, -1, -1, 1950, -1, -1, -1, -1, 1963, 885, -1, -1, 2190, 1255, -1, -1, -1, -1, 2216, 2625, -1, -1, 2389, -1, -1, -1, -1, -1, 1155, 2184, 1846, 1863, 2069, -1, -1, 361, 217, -1, -1, 1216, 633, -1, -1, -1, -1, -1, -1, 1302, 2364, -1, -1, 1256, 425, -1, -1, -1, 2591, 1308, 2146, -1, -1, 2758, -1, 1480, -1, -1, -1, -1, -1, -1, -1, 158, 743, -1, 2442, -1, -1, 2085, 1015, 1881, -1, -1, 1242, 1156, -1, -1, 1982, 1221, -1, -1, 1906, 1193, 39, 296, -1, 527, 1914, 902, 397, 1630, -1, -1, 546, -1, -1, -1, -1, 136, 2035, 2523, 1895, 1349, -1, -1, 2363, 1051, -1, 1698, -1, -1, -1, 387, 1134, -1, 458, 732, 373, -1, 2328, 1074, -1, -1, -1, -1, 2055, -1, -1, -1, 1138, 2267, 1021, 1735, 871, 1076, -1, -1, 2501, 347, -1, -1, 401, 2280, 1915, -1, 783, 1663, -1, 2723, 2088, 533, 2496, 2143, -1, -1, -1, 1247, 1635, 2301, -1, -1, -1, -1, -1, 981, -1, -1, -1, -1, -1, 658, 1969, 1046, -1, 451, 2234, -1, 1147, 2516, -1, -1, 1298, 670, -1, -1, 1842, 1610, -1, 2314, 441, 1643, -1, 1692, 715, 2107, -1, 1634, 2081, 846, 515, 1486, 2353, 2021, 862, 873, 1532, 782, 534, 2653, 1625, -1, 1565, 27, 2711, 1395, -1, -1, 2145, 659, 2778, -1, -1, -1, 1856, -1, 1588, 1679, -1, -1, 195, -1, 2148, 2347, -1, -1, 583, -1, -1, 2742, -1, -1, -1, 549, 877, 599, 243, 1673, -1, -1, -1, -1, 853, -1, -1, 79, -1, -1, 1741, 1422, -1, 917, -1, -1, -1, -1, 1498, 1841, 773, -1, 2023, 110, -1, -1, 2648, -1, 260, 504, 2666, 314, -1, 1808, 1720, 114, 2253, 1296, 1809, -1, 2003, -1, 2722, -1, -1, -1, -1, 1987, 163, -1, -1, 1170, -1, 1626, 2536, -1, -1, -1, 478, 1901, -1, -1, 1347, 2381, -1, -1, 389, -1, -1, -1, -1, 1383, -1, 780, 2461, -1, 496, -1, 2244, 675, 1094, -1, -1, 2076, -1, -1, 1327, 2172, -1, -1, -1, -1, 3, -1, 1702, 1822, -1, 1218, 619, 1546, 587, -1, -1, 2104, 1244, 157, 1254, -1, -1, -1, 820, 487, 1933, 728, -1, 794, -1, -1, -1, -1, -1, 2716, -1, -1, -1, 42, -1, -1, 2070, 2284, 2130, -1, -1, 1443, 2027, 431, 1416, 684, -1, -1, 1257, 2504, -1, 1551, -1, -1, -1, -1, -1, 833, -1, 350, 457, 2336, -1, -1, -1, -1, 1201, 1417, -1, -1, 60, -1, -1, -1, 1674, -1, -1, -1, 961, -1, 1921, -1, -1, -1, 2522, -1, 2660, 1031, 987, 1777, -1, -1, 1203, 2174, 1315, 286, -1, 2588, -1, 805, 1279, 2421, 403, -1, -1, 689, -1, 2574, -1, -1, 765, 2112, 1522, 2141, -1, -1, -1, 683, -1, -1, 1274, -1, 2765, -1, -1, 904, -1, -1, -1, -1, 896, -1, -1, 1338, -1, -1, 593, -1, -1, 40, -1, -1, -1, -1, 1623, -1, 2115, -1, -1, -1, -1, -1, -1, -1, -1, 192, -1, -1, 326, -1, -1, -1, 2256, 1622, 2245, -1, 1014, -1, -1, 2302, -1, -1, 261, 1424, 306, 305, 23, -1, 1598, -1, 2509, 1050, 55, -1, 312, -1, 2747, -1, -1, 325, -1, -1, -1, 901, 1423, 2787, 190, -1, 1030, 1802, -1, -1, -1, 251, 586, -1, -1, -1, 536, -1, -1, -1, -1, -1, -1, 1934, 98, 2769, -1, 2308, 855, 764, 519, -1, 1687, 264, 390, -1, -1, -1, -1, -1, -1, 235, 2229, -1, 953, -1, 1227, -1, 2198, -1, 31, -1, -1, -1, -1, 610, 551, -1, 289, 711, -1, 1378, -1, 492, 179, 2014, 17, -1, -1, 2449, -1, 1266, -1, 1664, 866, -1, 1789, 113, 796, -1, -1, 2022, -1, -1, -1, 628, 940, 919, 15, 1229, 2390, -1, -1, -1, -1, 1996, 1509, -1, 2582, -1, -1, -1, 1286, -1, 1225, -1, 1083, 2109, 1333, 378, 36, 1657, -1, -1, 618, 2453, 2594, 359, -1, 544, 2663, 4, 1992, -1, 1215, -1, 2480, 1421, 1184, 2100, 345, 2658, -1, 2317, -1, -1, -1, -1, -1, 1344, -1, -1, 2476, -1, -1, -1, -1, -1, -1, -1, -1, 657, -1, -1, -1, 863, -1, 509, -1, 1748, -1, 2057, 2209, 857, -1, 1125, 1281, 433, 1742, -1, -1, 85, 722, 905, 374, -1, 582, 834, -1, -1, 225, -1, -1, 2180, -1, -1, 1960, 2585, 265, -1, -1, 2661, 2419, 2337, -1, -1, 1737, -1, 1945, -1, -1, 988, -1, -1, 960, -1, 2320, 1827, -1, -1, -1, -1, 1382, 337, -1, 153, -1, 2497, 1340, -1, 1795, -1, -1, -1, -1, 1232, -1, -1, -1, 2676, -1, -1, 571, 1345, 319, -1, 1680, -1, 2662, -1, 935, -1, -1, -1, 806, -1, 2774, 2575, 1959, -1, -1, -1, -1, -1, 1668, -1, 1028, 1538, 1706, -1, 1169, -1, 1686, -1, -1, 2061, -1, 1018, -1, -1, -1, 1493, 2494, -1, -1, -1, -1, -1, -1, 681, -1, -1, -1, 984, 2775, -1, -1, -1, 1301, 946, 2782, -1, -1, -1, -1, 2704, 2654, -1, -1, 448, -1, -1, -1, -1, 803, -1, 2413, 395, -1, -1, -1, -1, 2448, -1, 386, 1955, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2762, 1312, 1109, -1, 1297, -1, 1586, 330, -1, -1, -1, -1, 1428, 1604, -1, -1, 759, -1, 1143, -1, -1, 1772, 576, 1122, 2185, -1, 859, -1, -1, 231, -1, -1, -1, -1, -1, -1, -1, -1, 685, -1, -1, 1272, 749, -1, -1, 600, 865, 156, -1, 2343, -1, -1, -1, -1, 1166, 777, -1, -1, 1391, 2737, -1, 1117, -1, -1, -1, -1, 1393, -1, 996, -1, -1, -1, -1, 1265, 1214, 1759, -1, -1, -1, -1, -1, -1, 909, -1, 798, 1220, -1, 1649, -1, 233, 1406, -1, -1, -1, -1, -1, -1, -1, -1, 1467, -1, 1196, -1, -1, -1, -1, 1832, -1, 423, 1025, -1, 713, 188, 1817, 837, 1446, 493, -1, 1096, -1, -1, -1, 2781, -1, 2429, 1084, -1, 2713, 2335, -1, -1, 1126, 476, 661, 847, -1, -1, -1, 2260, -1, 1527, -1, -1, 1237, -1, -1, 2471, -1, 1093, -1, -1, 2500, 1646, -1, -1, -1, 376, -1, 545, 903, 1053, 2631, -1, 1793, -1, 1245, -1, 2431, 1819, -1, -1, 1413, -1, -1, -1, -1, 2697, 247, -1, 1430, 1434, 2709, -1, 2207, 760, -1, -1, -1, 211, -1, -1, -1, 590, 705, -1, -1, 297, -1, 2250, 1454, 584, 540, -1, 91, -1, -1, 2589, -1, -1, -1, 2513, 2706, 2439, -1, -1, -1, -1, -1, 33, -1, -1, 1575, -1, 1736, 204, -1, -1, 301, 2271, 665, 1985, 2313, -1, 1005, -1, -1, -1, 925, 738, -1, 1115, -1, 1870, 721, -1, 2350, 53, -1, -1, -1, -1, 2385, 1514, 2455, 1653, -1, 1839, -1, 2614, 2610, -1, -1, 936, -1, -1, 2537, 2620, 1319, -1, 2479, 1528, -1, 1520, -1, 1550, -1, -1, 1840, -1, 653, -1, 1675, 1995, 845, -1, -1, -1, 2686, 1426, 2170, -1, -1, -1, -1, -1, -1, 569, 2132, 547, 2524, -1, 2779, -1, 2452, 2534, 1877, 1457, -1, 97, -1, -1, -1, -1, -1, 2415, 2402, 1813, -1, -1, 1284, -1, 253, -1, -1, 1392, -1, 1024, -1, 1838, 2651, 1552, 858, 1, -1, 224, -1, -1, 323, -1, 2089, 978, 1341, -1, 575, -1, 1676, 979, -1, 248, -1, -1, 1651, -1, 1884, -1, 2283, -1, -1, -1, -1, 2596, 1310, -1, 2531, -1, -1, 413, 1066, 1072, -1, 592, 257, 513, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 405, -1, 2224, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2573, 560, 2482, 367, 757, -1, -1, -1, -1, -1, 1648, -1, -1, 1385, -1, -1, -1, -1, -1, 240, -1, -1, 2004, -1, 2006, -1, 1591, 2009, 2010, 2011, 2012, 2013, -1, -1, 2016, 2017, 801, -1, 2020, -1, -1, -1, -1, 307, 2026, -1, 2028, 2029, 1185, 2031, -1, 2033, 2034, 61, 2036, 497, 2038, -1, 2040, 2041, 2042, -1, -1, -1, 2046, -1, 2048, 2049, 28, 144, 2052, 2053, 2054, -1, 2056, -1, -1, -1, 2060, -1, 2062, 2063, 2064, 1890, 2066, 2067, 2068, 1277, -1, 2071, 1595, 2073, 1707, 2075, -1, 1236, 2078, 1335, 1983, -1, 949, -1, 2084, 384, 2086, 2087, 1658, 660, -1, 2091, 2092, -1, 2094, 2095, 2096, 2097, 2098, 1516, -1, 1847, 2102, -1, 630, 2105, 2106, 1607, 2108, -1, 2110, 2111, -1, 2113, 2114, -1, 2116, 2117, 1654, 2119, -1, 2121, 2122, -1, 2124, -1, 2126, 2127, 2128, 414, -1, -1, -1, 2133, 54, -1, 2136, 2137, 2138, 2139, 2140, -1, 2142, -1, 2144, 1091, -1, 2147, 1924, 2149, 2150, 2151, 2152, 2153, 2154, 2155, -1, 2157, -1, 2159, 2160, -1, 2162, 2163, 2164, 2165, 230, 2167, 2168, 2169, -1, 2171, -1, 2173, -1, 112, 1299, 2177, -1, 2179, 141, 298, 2182, 2183, -1, -1, 2186, -1, 2188, 2189, -1, 1986, 2192, 2193, 2194, 2195, 700, 242, -1, 2199, -1, 2201, -1, 2203, 2204, 21, -1, 267, 2208, -1, 2210, -1, -1, 2213, 2214, 2215, -1, 1390, 2218, 2219, 2220, -1, 1198, 2223, 1640, 2225, 2226, 2227, 2228, 876, 2230, 2231, 2232, 2233, -1, 2235, 2236, 1711, 2238, 159, 1471, 2241, 63, -1, 1183, -1, 2246, 1972, 2248, 2249, -1, 198, 2252, -1, 2254, 2255, -1, 2257, 2258, -1, -1, 2261, 526, 2263, 2264, 485, 2266, 1778, 1866, 2269, -1, -1, 138, 2273, 2274, -1, 2276, 1967, 1448, 2279, -1, 2281, 2282, -1, -1, 2285, 418, 2287, 2288, 75, -1, 2291, 207, 2293, 2294, 2295, 1120, -1, 1407, -1, 2300, -1, -1, 118, 2304, -1, 2306, 2307, 398, 2309, -1, 2311, -1, -1, -1, 2315, 2316, -1, 2318, 2319, -1, 2321, 2322, 1543, -1, -1, -1, 888, -1, 2329, 2330, 2331, 2332, 2333, 829, 124, -1, 640, 1601, 2339, 2340, 2341, 2342, -1, 2344, 2345, 2346, 228, 2348, 2349, -1, 2351, 2352, -1, -1, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, -1, -1, 2365, 176, 2367, -1, 2369, 2370, -1, -1, 474, 2374, -1, 2376, 2377, 2378, 100, -1, -1, -1, 2383, 2384, 572, 2386, 2387, 848, -1, -1, 2391, 2392, 2393, 2394, -1, 174, 1796, 1239, 2399, 105, -1, -1, 2403, -1, 2405, 2406, 2407, 2408, 1129, 2410, 2411, 2412, 1439, 2414, 304, 2416, 2417, 1539, 735, 2420, -1, 2422, 2423, 2424, 2425, 2426, 2427, -1, -1, 2430, 2077, 2432, 2433, 2434, -1, 2436, 2437, 1355, 1375, 2440, -1, -1, -1, -1, 2445, 552, 1621, -1, 170, 2450, 1162, -1, -1, 2454, -1, 2456, 452, 2458, -1, 83, 444, 1733, 1112, -1, 2465, 2466, 2467, -1, 2469, 20, -1, 1504, 2473, -1, 2475, -1, -1, 2478, -1, -1, 1054, -1, 2483, 2484, 472, 2486, -1, 2488, 2489, 2490, 2491, 966, 864, -1, 531, 1450, -1, 2498, 2499, 1026, 973, 2502, 603, -1, 577, 2506, 2507, -1, 507, 1176, -1, 678, 1438, 2514, 2515, -1, 2517, 2518, 2519, 2520, 2521, -1, -1, -1, 2525, 2526, -1, 2528, 2529, 2530, -1, 2532, 2533, -1, 2535, -1, 1729, -1, 2539, 1212, -1, 2542, -1, 1602, 2545, -1, 2547, 470, 2549, 2550, 2551, 2552, -1, -1, 2555, 2556, 2557, 2558, 2559, 729, 2561, 2562, 2563, -1, -1, 89, -1, 2568, 730, 2570, 2571, 2572, -1, 740, 1903, -1, 2577, 2578, 2579, 2580, 2581, -1, 2583, 2584, -1, 2586, 2587, 1397, -1, -1, -1, 2592, 2593, 1730, 2595, -1, 2597, 1263, -1, 2600, 199, -1, 2603, 2604, -1, -1, -1, -1, -1, -1, -1, 2612, 2613, -1, -1, 2616, 1294, 1563, 2619, -1, 2621, 2622, -1, 573, -1, 2626, -1, 2628, 2629, 1633, -1, 2632, -1, 2634, 741, 2636, 2637, 2638, -1, 1609, 2641, 1712, 2643, 2644, 2645, 2646, 636, -1, 2649, 2650, -1, 2652, -1, -1, 2655, 396, 2657, -1, 2659, -1, -1, 1507, 194, 2664, -1, -1, 2667, -1, 2669, 2670, 2671, 2672, 1872, 2674, 2675, -1, 2677, -1, 2679, 2680, 1919, 2682, 2683, 2684, 456, 480, -1, 2688, 2689, 2690, -1, 1981, 2693, 2694, 2695, 2696, -1, 210, 2699, 664, 2701, 1618, 2703, 1293, 2705, -1, -1, 2708, -1, 746, -1, -1, -1, -1, 2715, -1, 2717, 1997, 2719, 2720, 2721, -1, -1, 2724, 562, -1, 2727, 2728, 2729, 399, 2731, 2732, 539, 2734, -1, 417, 538, 2738, 2739, -1, 288, -1, 2743, 2744, 2745, 2746, -1, 2748, 2749, 2750, 937, 2752, 2753, 2754, 2755, 2756, 638, 1495, 2759, 2760, 2761, -1, -1, 2764, -1, 2766, 1943, 2768, -1, -1, 2771, 2772, 1594, -1, -1, -1, 2777, 43, -1, 2780, 203, -1, 2783, -1, 2785, -1, 1303, 2788, -1, 2790, 2791, -1, 2793, 2794, 2795, -1, 2797, 2798, 215]\n"
     ]
    }
   ],
   "source": [
    "### UPDATE Z ###\n",
    "\n",
    "# update linkage z_j\n",
    "\n",
    "new_z = []\n",
    "file_AB = AB.copy()\n",
    "file_B = B.copy()\n",
    "file_A = A.copy()\n",
    "\n",
    "theta_m = theta_m_k[-1]\n",
    "theta_u = theta_u_k[-1]\n",
    "mu2 = mu2_k[-1]\n",
    "sigma2_square = sigma2_square_k[-1]\n",
    "\n",
    "beta0 = beta0_k[-1]\n",
    "beta1 = beta1_k[-1]\n",
    "alpha = alpha_k[-1]\n",
    "\n",
    "z = z_k[-1]\n",
    "alpha_pi_k = [1]\n",
    "beta_pi_k = [1]\n",
    "beta_pi = beta_pi_k[-1]\n",
    "alpha_pi = alpha_pi_k[-1]\n",
    "\n",
    "already_taken = []\n",
    "\n",
    "for fixed_j in range(file_B.shape[0]):\n",
    "\n",
    "    comparison_for_j = comparison_vectors_only[file_AB.source_index_B==fixed_j].copy()\n",
    "\n",
    "    w1 = ( np.multiply( comparison_for_j, np.log(theta_m/theta_u) ) + np.multiply( 1-comparison_for_j, np.log((1-theta_m)/(1-theta_u)) ) ).sum(axis=1)\n",
    "\n",
    "    w2_unmatched_outcome = scipy.stats.norm.pdf(file_AB[file_AB.source_index_B==fixed_j].Y, mu2, np.sqrt(sigma2_square))\n",
    "\n",
    "    data_for_j = file_AB[file_AB.source_index_B==fixed_j].copy()\n",
    "    residuals = data_for_j.Y - np.array([data_for_j.intercept, data_for_j.propensity_score, data_for_j.propensity_score * data_for_j.treatment]).T @ np.array([beta0, beta1, alpha]).T\n",
    "    residuals_variance = residuals.T @ residuals / (len(residuals) - (3+1))\n",
    "\n",
    "    w2_matched_outcome = scipy.stats.norm.pdf(residuals, 0, np.sqrt(residuals_variance))\n",
    "\n",
    "    w2 = np.log(w2_matched_outcome/w2_unmatched_outcome)\n",
    "\n",
    "    probabilities = np.array(np.exp(w1+w2))\n",
    "\n",
    "    choice_array = list(filter(lambda x: x not in already_taken, np.arange(file_A.shape[0])))\n",
    "    probabilities = probabilities[choice_array]\n",
    "\n",
    "    choice_array = np.append(choice_array, -1)\n",
    "    others = np.delete(z, fixed_j)\n",
    "    n_AB_ = (others>=0).sum()\n",
    "    proba_no_link = (file_A.shape[0] - n_AB_) * (file_B.shape[0] - n_AB_ - 1 + beta_pi) / (n_AB_ + alpha_pi)\n",
    "    probabilities = np.append(probabilities, proba_no_link)\n",
    "    \n",
    "    val = np.random.choice(choice_array, p = probabilities / sum(probabilities))\n",
    "    if val != -1:\n",
    "        already_taken.append(val)\n",
    "    \n",
    "    new_z.append(val)\n",
    "\n",
    "print(new_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, 2382, -1, 2691, 1965, -1, -1, -1, -1, 977, 1305, 2359, -1, -1, 1953, 1735, 956, 2046, -1, -1, -1, 1240, -1, 793, -1, -1, 1363, -1, 342, -1, -1, 1384, 1852, -1, -1, -1, 1283, 131, 429, -1, -1, 2066, 2297, -1, 1264, -1, -1, 1715, -1, 332, 2608, 331, -1, -1, -1, 872, -1, -1, 881, -1, 1782, 816, -1, -1, 1182, -1, -1, -1, -1, -1, 2728, 1103, 495, -1, 566, 471, -1, -1, 565, -1, 1082, -1, -1, 2039, 2059, -1, 469, 1249, -1, 1485, 1531, -1, 1187, 399, 639, 1804, -1, -1, 1525, 1141, 445, -1, -1, -1, -1, 874, 638, 1579, 1713, -1, -1, -1, -1, 147, 2181, -1, 676, -1, -1, -1, 2275, -1, 821, -1, 2238, -1, 652, 65, -1, -1, 885, 1719, -1, -1, 1255, -1, -1, 2624, -1, 2216, 2625, -1, -1, 2389, -1, -1, -1, -1, -1, 1155, 2184, 1846, -1, 1277, -1, -1, 361, 217, -1, -1, -1, 633, -1, -1, 46, -1, -1, -1, -1, 2364, 654, -1, 1256, 425, -1, 11, -1, 2591, 1308, 2146, -1, -1, -1, -1, -1, -1, -1, -1, -1, 949, 2492, -1, -1, 743, -1, 2442, -1, 522, 384, 1015, 1881, -1, -1, 1242, -1, -1, -1, -1, 1221, 2593, -1, 1906, 1193, 39, 296, -1, -1, 1914, 902, 397, 1630, -1, -1, 546, 1620, 9, -1, -1, 136, 2035, 2523, 1895, -1, -1, 739, -1, -1, -1, 1698, -1, -1, 1121, 387, 1134, -1, 458, 732, 373, -1, 2328, 1074, -1, -1, -1, -1, 2055, -1, -1, -1, 1138, 1778, 1021, -1, 871, -1, -1, 2152, 2501, 347, -1, -1, 401, 2280, -1, 1902, 783, -1, -1, 2723, 1658, 533, -1, 2143, -1, -1, -1, 1247, 1635, 2301, 1165, -1, -1, -1, 229, 981, -1, 432, -1, -1, -1, 658, 1969, -1, 2499, 451, -1, 1462, 1147, -1, -1, 1012, 1298, -1, 906, -1, 1842, -1, -1, 2314, -1, 1643, -1, 1692, -1, 1607, 1190, 1634, -1, 2752, 515, -1, -1, -1, -1, 873, 1532, 782, 534, -1, 1625, 369, 1565, -1, 2711, -1, -1, -1, 1091, 659, 43, -1, 58, -1, 1856, -1, 1588, 1679, 1627, -1, 195, -1, 1924, -1, -1, -1, 583, -1, -1, -1, 1561, -1, -1, 549, 877, 1767, -1, 1673, -1, -1, -1, -1, 853, -1, -1, 79, -1, -1, 1741, 1422, -1, -1, -1, -1, -1, 2140, 1498, 1841, 773, -1, 2023, 110, -1, -1, 2648, -1, 260, -1, 2666, 314, 2226, 1808, 1720, 114, 2253, -1, -1, -1, 1798, -1, 2722, -1, -1, -1, -1, 1987, 2738, -1, -1, -1, -1, 1626, 2536, -1, 1372, -1, 478, 2680, -1, -1, 1347, 2381, 625, 1684, 389, -1, 1689, -1, -1, -1, -1, 780, 444, 2764, -1, -1, 2244, 675, 1094, -1, -1, 2076, -1, -1, 559, 2172, -1, -1, 1535, -1, 3, -1, -1, 1822, -1, -1, 619, 1546, 587, -1, 1957, -1, 1244, 157, 1254, -1, -1, -1, 820, 487, 1933, 728, -1, 794, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2284, 2130, 86, -1, 1443, 2027, -1, 1416, 684, 2692, -1, 2204, 1482, -1, -1, 1059, -1, -1, -1, -1, -1, -1, 350, 457, 2336, 1408, -1, -1, -1, 1201, 1417, -1, -1, 60, -1, -1, -1, 1674, 1079, -1, -1, 961, 268, -1, -1, -1, -1, 2522, -1, 2660, 1031, 987, 1777, -1, 1161, 1203, -1, 1315, 286, 648, 2588, -1, -1, 1279, 2421, 403, -1, -1, -1, -1, 740, -1, -1, 765, 2112, 1522, 2141, -1, -1, -1, -1, -1, 123, -1, -1, 2765, -1, -1, 904, -1, -1, -1, -1, -1, -1, -1, 1338, -1, -1, -1, -1, -1, 40, -1, -1, -1, -1, 1623, -1, 2115, -1, -1, -1, 851, -1, -1, -1, -1, -1, 2409, -1, 326, -1, -1, -1, 2256, 1622, 2245, -1, 1014, 2410, -1, 557, 1747, -1, -1, 1424, 306, 305, 2696, -1, 1598, 2699, 2509, 1050, 55, -1, 312, 616, 2747, -1, 333, 2258, -1, 181, -1, 901, 1423, 2787, 2102, -1, 1030, 1802, -1, -1, -1, 251, 2547, -1, 1248, 2609, 536, -1, -1, -1, -1, -1, -1, 1934, -1, 2769, -1, 398, -1, 764, 519, -1, 1687, 264, 390, -1, -1, -1, -1, -1, -1, 235, 876, -1, 953, -1, -1, -1, 2198, -1, 31, -1, -1, 455, -1, 610, 551, -1, 289, 711, -1, 1378, -1, 997, 179, 2014, 17, 2508, -1, 170, -1, 1266, -1, -1, -1, -1, 1789, 113, 796, -1, -1, 2022, 1346, -1, -1, 628, 2111, 919, 15, 1229, 2390, -1, -1, -1, -1, 1996, 1509, -1, 2582, -1, 430, 1883, 1286, 64, 1225, -1, 1083, 2109, 1333, 378, 36, 1657, 396, -1, 618, 2453, 1730, 359, -1, 544, 2663, 4, 1992, -1, 1215, 2581, 2480, 1421, 1184, 2100, 345, 2658, 2584, 2317, -1, -1, -1, -1, -1, 1344, -1, -1, 576, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 863, -1, 509, -1, 1748, -1, 2057, -1, 857, -1, 1651, -1, -1, -1, -1, -1, 85, 722, 905, 374, -1, 582, 834, -1, 1118, 225, -1, -1, -1, -1, 1223, -1, 2585, 265, -1, -1, 2661, -1, 640, -1, -1, -1, -1, 1945, -1, 1139, 988, -1, -1, 960, -1, 1941, -1, -1, -1, -1, -1, -1, 337, -1, -1, -1, -1, 1340, -1, 1037, 1580, -1, -1, -1, 1232, -1, -1, -1, 2676, 503, -1, -1, 1345, 319, -1, 1680, -1, 1507, -1, 935, 1614, -1, -1, 806, -1, 2774, 2575, -1, -1, 1386, -1, -1, -1, 1668, 1696, 1028, 1538, 1706, -1, 1169, -1, -1, 791, -1, 2061, -1, 2784, -1, -1, -1, -1, 2494, -1, -1, 1757, -1, -1, -1, 2432, -1, -1, -1, 984, -1, -1, -1, 580, -1, -1, 2782, -1, -1, -1, 1090, 2704, 2654, -1, -1, -1, -1, -1, 752, -1, 803, -1, -1, 395, -1, -1, -1, -1, 2448, -1, 386, 2218, -1, -1, -1, -1, 2054, -1, -1, -1, -1, 164, 1312, 1109, -1, 1297, 1910, 1586, 330, -1, -1, 2682, -1, 1428, 1604, -1, -1, 759, -1, 1143, -1, -1, 1772, -1, 1122, 1148, -1, 859, 483, -1, 231, -1, -1, -1, -1, -1, -1, -1, 1970, -1, -1, -1, 1272, 2616, -1, 2466, 600, 865, 156, 13, 2343, -1, -1, -1, -1, 2230, 777, 2441, -1, -1, 538, 641, 1117, -1, 2670, -1, -1, 1393, 241, -1, -1, -1, -1, -1, 1265, 1214, 1759, 1779, 2324, -1, 2790, 1092, 1099, -1, -1, 798, -1, -1, 1649, -1, 233, 1406, -1, -1, 2008, -1, -1, 1766, -1, 1803, -1, -1, 1196, -1, -1, -1, -1, 1832, -1, 2664, 1025, -1, 713, 188, 1817, 837, 1446, 493, -1, 1096, -1, 1325, -1, -1, -1, 2429, 1084, -1, 2713, 2335, -1, -1, -1, 476, 661, 847, 322, -1, -1, 2260, -1, 1527, -1, -1, 1237, -1, -1, -1, 2348, 1093, -1, 1460, 1026, 1646, -1, 523, 1830, 376, -1, -1, -1, 1053, 2631, -1, 1793, -1, 1245, 570, -1, -1, 775, 2315, 1413, -1, -1, -1, -1, 2697, 247, -1, 1430, -1, 2709, -1, 267, 760, -1, -1, 2214, 211, 1962, -1, -1, 590, 705, -1, 1320, 297, -1, 2250, -1, 584, 540, -1, -1, -1, -1, 2589, 1436, 1480, -1, 1438, -1, 1375, -1, -1, -1, -1, 518, 33, -1, -1, -1, 151, 1736, 204, -1, 2611, -1, 2271, 665, 1985, -1, -1, 2114, -1, -1, -1, -1, 738, -1, -1, -1, 1870, 721, -1, 2350, 53, -1, -1, -1, -1, 2385, 1514, 2455, 2571, -1, -1, -1, 2614, -1, -1, 1898, 936, 1062, -1, -1, -1, 1319, -1, 2479, 1528, -1, 1520, -1, 1550, -1, -1, -1, -1, 653, -1, -1, 1995, -1, -1, -1, -1, 480, 1426, -1, -1, 525, -1, -1, -1, -1, 569, 2132, 547, 2524, -1, 2779, -1, -1, -1, 1877, 1457, -1, 97, -1, -1, -1, -1, -1, 2415, 2402, 2274, -1, -1, -1, -1, 253, -1, -1, -1, -1, 1024, 189, 1838, 2651, -1, -1, 1, -1, 224, -1, -1, 323, 2601, 2089, -1, 1341, -1, 2514, -1, 1676, 979, -1, 248, -1, 2550, -1, -1, 1884, 184, 2283, -1, -1, 1116, -1, 2596, 1310, -1, 2531, -1, -1, 413, -1, -1, -1, 592, -1, 513, 1400, -1, 1440, -1, -1, -1, -1, -1, -1, -1, 405, -1, 1640, -1, -1, -1, -1, -1, -1, -1, 2785, -1, 2573, 560, 2482, -1, 757, -1, -1, -1, -1, -1, 1648, -1, -1, 1385, -1, -1, -1, -1, 2000, 2001, 2002, -1, 2004, 2005, 2006, 2007, 1591, 2009, 2010, 1599, 2012, 2013, -1, 2015, -1, 2017, 1360, 115, -1, 2021, -1, -1, -1, 307, 2026, -1, 2028, 2029, 1185, 2031, 2032, 2033, 2034, -1, 1045, 2037, -1, -1, 1189, 461, 2042, 2043, 835, -1, 1739, 2047, 2048, 2049, 2050, 144, 2052, 2053, -1, -1, 2056, -1, 2058, -1, 300, -1, 1628, 792, 1290, 2065, -1, 2067, 2068, 2069, 2070, 2071, 2072, -1, 1707, 2075, -1, 2077, 1070, 2079, 1983, 2081, 2082, 2083, 2084, 2085, 1036, 2087, 2088, 660, -1, 2091, 2092, -1, -1, 2095, 255, 2097, 416, -1, -1, 1847, 190, -1, -1, 2105, 2106, 2107, -1, -1, -1, 940, -1, 886, -1, -1, 2116, -1, -1, 2119, 2120, -1, 2122, -1, 2124, 2125, 2126, 2127, 2128, 2129, -1, 2131, -1, 1427, 2134, 2135, 2136, 2137, 2138, 2139, 704, -1, 1135, 2574, -1, 2145, -1, 2147, 2148, 2149, -1, 1492, -1, 2153, 2154, 2155, 2156, 2157, 2158, 2159, -1, 317, 1179, 2163, -1, 2165, 2166, 2167, 2168, 2169, 2170, 2171, -1, 2173, 2174, 112, 2176, 2177, 2178, 2179, 141, -1, -1, 2183, -1, 2185, 2186, 1326, -1, 2189, -1, 1986, 2192, 2193, 2194, 2195, 2196, 2197, -1, 2199, 364, 2201, 2202, 2203, 1257, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, -1, -1, -1, 2217, 1955, 2219, 2220, 2221, 2222, -1, 2224, 2225, -1, 269, -1, -1, 1166, 2231, 1911, 2233, 2234, 2235, -1, 1711, 1950, 2239, 1471, 564, -1, -1, 1183, -1, 273, 1972, 1699, -1, -1, 2251, 2252, -1, 2254, 2255, -1, 2257, -1, 2259, -1, 1065, 526, -1, -1, 2265, 1295, 2267, 1866, -1, -1, 1807, 138, 2273, 1813, -1, 2276, 2277, 2278, 2279, -1, 929, 2282, -1, -1, 2285, 2286, 2287, 2288, -1, 2290, 2291, 207, 2293, 2294, -1, 1120, -1, 1407, 2299, 2300, -1, 2302, 118, -1, 2305, 2306, 2307, 2308, 2309, -1, 2311, 2312, 2313, -1, 965, -1, -1, 2318, 2319, 2320, 2321, 435, 1543, -1, 2325, -1, 888, -1, 2329, 2330, 2331, 2332, 2333, 2334, 124, -1, -1, 1601, 2339, 2340, 2341, 2342, -1, 2344, 2345, 2346, 2347, 1927, 2349, -1, -1, 2352, 2353, -1, 2355, 2356, 2357, 1027, -1, -1, 2361, 2362, 2363, -1, -1, 2366, -1, 2368, 2369, 2370, 1508, -1, 474, 2374, 2375, 2376, 2377, 2378, 2379, -1, -1, -1, 2383, 2384, 572, -1, 2387, 2388, -1, -1, 2391, 595, 2393, 2394, -1, 174, 2397, 2398, 2399, 2400, 666, -1, 2403, 2404, 2405, 2406, -1, -1, 1129, -1, 2411, 2412, 2413, 2414, 304, 1419, 2417, 2418, -1, 1314, -1, 2422, 2423, -1, 2425, -1, 1269, 671, -1, 2430, 2431, 681, -1, 2434, 2435, 2436, 2437, 1355, 2439, 2440, 1758, -1, -1, -1, -1, -1, 2447, -1, -1, 2450, -1, 2452, -1, 2454, -1, 243, 452, 348, 2459, 2460, 2461, 2462, -1, 2464, 882, 1478, -1, 2468, 2469, 20, 2471, 1504, 2473, 2474, 2475, 1755, 2477, 787, -1, -1, 2481, -1, 2483, -1, 2485, -1, 2487, 2488, 2489, 644, 2491, 966, 864, -1, 531, 1450, 2497, -1, -1, 2500, 973, 2502, 2503, 2504, 2505, -1, 2507, -1, 507, -1, 2511, 2512, 2513, 575, -1, -1, 2517, 2518, -1, 2520, 125, -1, -1, -1, 2525, 2526, 2527, 2528, 1209, 2530, -1, 2532, 2533, 2534, 2535, -1, -1, -1, 921, 2540, -1, -1, 2543, 2544, 2545, 2546, 586, 2548, 2549, -1, 2551, 2552, 2553, -1, -1, 2556, 2557, 2558, 1587, 2560, 2561, 2562, 1102, 2564, -1, 2566, 2567, -1, 2569, 2570, 1653, -1, -1, -1, 1903, -1, 2577, 2578, 542, 1151, -1, 927, 1728, -1, -1, 2586, 2587, 1397, -1, 2590, -1, -1, -1, 2594, 2595, -1, 2597, 1263, 2599, 2600, 199, 2602, 771, 2604, -1, -1, -1, -1, -1, 2610, -1, 2612, 183, -1, -1, 749, 1294, 1563, -1, 2620, -1, 1652, 2623, -1, -1, 1001, 1791, -1, 2629, -1, -1, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 1056, 2640, 2641, 1712, -1, -1, 2645, -1, 636, -1, 2649, 261, -1, 119, 2653, -1, 2655, 2656, 1820, -1, 2659, -1, -1, 2662, 194, 423, -1, -1, 2667, 1227, 2669, -1, 2671, -1, 1872, 2674, 2675, -1, 2677, -1, 2679, -1, 2681, 1126, 2683, 2684, 2685, 2686, 2687, -1, 2689, 2690, -1, 1981, 2693, 2694, 2695, 23, -1, 2698, -1, 664, 2701, 995, -1, -1, 2705, 2706, 2707, -1, -1, 2710, -1, 2712, -1, 299, 2715, -1, 78, 2718, 2719, -1, 2721, -1, -1, 2724, 2725, 2726, 2727, 388, 2729, 2730, 1111, 2732, 2733, 1219, 2735, 417, 2737, 163, 2739, 1503, 2741, -1, 2743, 1951, 2745, 578, -1, 2748, 2749, 2750, 2751, 846, 2753, 2754, 2755, 2756, -1, 1495, 2759, 2760, 2761, 2762, 2763, -1, -1, 2766, 1943, 2768, -1, 2770, 412, 422, 1594, -1, 2775, -1, 2777, -1, -1, 2780, 2781, -1, 2783, 1018, -1, -1, 1303, 2788, 2789, 1042, 2791, 2792, -1, 2794, -1, 234, 2797, 2798, 215]\n"
     ]
    }
   ],
   "source": [
    "### UPDATE Z ### OPTI NEW\n",
    "\n",
    "# update linkage z_j\n",
    "\n",
    "new_z = []\n",
    "file_AB = AB.copy()\n",
    "file_B = B.copy()\n",
    "file_A = A.copy()\n",
    "\n",
    "theta_m = theta_m_k[-1]\n",
    "theta_u = theta_u_k[-1]\n",
    "mu2 = mu2_k[-1]\n",
    "sigma2_square = sigma2_square_k[-1]\n",
    "\n",
    "beta0 = beta0_k[-1]\n",
    "beta1 = beta1_k[-1]\n",
    "alpha = alpha_k[-1]\n",
    "\n",
    "z = z_k[-1]\n",
    "alpha_pi_k = [1]\n",
    "beta_pi_k = [1]\n",
    "beta_pi = beta_pi_k[-1]\n",
    "alpha_pi = alpha_pi_k[-1]\n",
    "\n",
    "already_taken = []\n",
    "\n",
    "comparison_vectors = comparison_vectors_only.copy()\n",
    "w1 = ( np.multiply( comparison_vectors, np.log(theta_m/theta_u) ) + np.multiply( 1-comparison_vectors, np.log((1-theta_m)/(1-theta_u)) ) ).sum(axis=1)\n",
    "w2_unmatched_outcome = scipy.stats.norm.pdf(file_AB.Y, mu2, np.sqrt(sigma2_square))\n",
    "X = np.array([file_AB.intercept, file_AB.propensity_score, file_AB.propensity_score * file_AB.treatment]).T\n",
    "BETA = np.array([beta0, beta1, alpha]).T\n",
    "residuals = file_AB.Y - X @ BETA\n",
    "# REMARK: X  in the residuals computation never evolve since we are using cartesian_product_AB file with all \"potential links\"\n",
    "residuals_variance = residuals.T @ residuals / (len(residuals) - (X.shape[1]+1))\n",
    "w2_matched_outcome = scipy.stats.norm.pdf(residuals, 0, np.sqrt(residuals_variance))\n",
    "w2 = np.log(w2_matched_outcome/w2_unmatched_outcome)\n",
    "probabilities = np.array(np.exp(w1+w2))\n",
    "probabilities = probabilities.reshape(file_B.shape[0], file_A.shape[0])\n",
    "\n",
    "n_AB_ = np.array([ (np.delete(z, j)>=0).sum() for j in range(file_B.shape[0]) ])\n",
    "\n",
    "proba_no_link = (file_A.shape[0] - n_AB_) * (file_B.shape[0] - n_AB_ - 1 + beta_pi) / (n_AB_ + alpha_pi)\n",
    "proba_no_link = proba_no_link.reshape(-1,1)\n",
    "\n",
    "#print(probabilities.shape)\n",
    "\n",
    "for fixed_j in range(file_B.shape[0]):\n",
    "\n",
    "    proba_vector = probabilities[fixed_j,:]\n",
    "    #print(proba_no_link[fixed_j,:])\n",
    "\n",
    "    choice_array = list(filter(lambda x: x not in already_taken, np.arange(file_A.shape[0])))\n",
    "    proba_vector = proba_vector[choice_array]\n",
    "\n",
    "    #print(len(choice_array), len(proba_vector))\n",
    "\n",
    "    choice_array = np.append(choice_array, -1)\n",
    "    #others = np.delete(z, fixed_j)\n",
    "    #n_AB_ = (others>=0).sum()\n",
    "    # proba_no_link = (file_A.shape[0] - n_AB_) * (file_B.shape[0] - n_AB_ - 1 + beta_pi) / (n_AB_ + alpha_pi)\n",
    "    proba_vector = np.append(proba_vector, proba_no_link[fixed_j,:])\n",
    "    #print(proba_vector)\n",
    "    #\n",
    "    #proba_vector = np.concatenate([probabilities, proba_no_link], axis = 1)\n",
    "    proba_vector = proba_vector / proba_vector.sum() #np.divide(proba_vector.T, proba_vector.sum(axis=1)).T\n",
    "    \n",
    "    val = np.random.choice(choice_array, p = proba_vector)\n",
    "    if val != -1:\n",
    "        already_taken.append(val)\n",
    "    \n",
    "    new_z.append(val)\n",
    "\n",
    "print(new_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "### UPDATE Z ### ### OPTIMIZE !!! ###\n",
    "\n",
    "# update linkage z_j\n",
    "\n",
    "new_z = []\n",
    "file_AB = AB.copy()\n",
    "file_B = B.copy()\n",
    "file_A = A.copy()\n",
    "\n",
    "theta_m = theta_m_k[-1]\n",
    "theta_u = theta_u_k[-1]\n",
    "mu2 = mu2_k[-1]\n",
    "sigma2_square = sigma2_square_k[-1]\n",
    "\n",
    "beta0 = beta0_k[-1]\n",
    "beta1 = beta1_k[-1]\n",
    "alpha = alpha_k[-1]\n",
    "\n",
    "z = z_k[-1]\n",
    "alpha_pi_k = [1]\n",
    "beta_pi_k = [1]\n",
    "beta_pi = beta_pi_k[-1]\n",
    "alpha_pi = alpha_pi_k[-1]\n",
    "\n",
    "already_taken = []\n",
    "\n",
    "comparison_vectors = comparison_vectors_only.copy()\n",
    "\n",
    "#for fixed_j in range(file_B.shape[0]):\n",
    "\n",
    "    #print(fixed_j)\n",
    "\n",
    "    #fixed_j = 3\n",
    "\n",
    "w1 = ( np.multiply( comparison_vectors, np.log(theta_m/theta_u) ) + np.multiply( 1-comparison_vectors, np.log((1-theta_m)/(1-theta_u)) ) ).sum(axis=1)\n",
    "\n",
    "w2_unmatched_outcome = scipy.stats.norm.pdf(file_AB.Y, mu2, np.sqrt(sigma2_square))\n",
    "\n",
    "X = np.array([file_AB.intercept, file_AB.propensity_score, file_AB.propensity_score * file_AB.treatment]).T\n",
    "BETA = np.array([beta0, beta1, alpha]).T\n",
    "residuals = file_AB.Y - X @ BETA\n",
    "# REMARK: X  in the residuals computation never evolve since we are using cartesian_product_AB file with all \"potential links\"\n",
    "residuals_variance = residuals.T @ residuals / (len(residuals) - (X.shape[1]+1))\n",
    "\n",
    "w2_matched_outcome = scipy.stats.norm.pdf(residuals, 0, np.sqrt(residuals_variance))\n",
    "\n",
    "w2 = np.log(w2_matched_outcome/w2_unmatched_outcome)\n",
    "\n",
    "probabilities = np.array(np.exp(w1+w2))\n",
    "probabilities = probabilities.reshape(file_B.shape[0], file_A.shape[0])\n",
    "\n",
    "#print(\"proba shape\", probabilities.shape)\n",
    "\n",
    "n_AB_ = np.array([ (np.delete(z, j)>=0).sum() for j in range(file_B.shape[0]) ])\n",
    "#print(n_AB_)\n",
    "#print(\"choice shape\", choice_array.shape)\n",
    "\n",
    "proba_no_link = (file_A.shape[0] - n_AB_) * (file_B.shape[0] - n_AB_ - 1 + beta_pi) / (n_AB_ + alpha_pi)\n",
    "#print(proba_no_link)\n",
    "#print(proba_no_link.reshape(-1,1))\n",
    "proba_no_link = proba_no_link.reshape(-1,1)\n",
    "#print(\"proba no shape\", proba_no_link.shape)\n",
    "probabilities = np.concatenate([probabilities, proba_no_link], axis = 1)\n",
    "#print(\"proba shape\", probabilities.shape)\n",
    "\n",
    "for fixed_j in range(file_B.shape[0]):\n",
    "    \n",
    "    choice_array = list(filter(lambda x: x not in already_taken, np.arange(A.shape[0])))\n",
    "    choice_array = np.append(choice_array, -1)\n",
    "    choice_array = np.tile(choice_array, file_B.shape[0]).reshape(file_B.shape[0], file_A.shape[0]+1)\n",
    "\n",
    "    probabilities = probabilities[:,choice_array]\n",
    "    proba_vector = np.divide(probabilities.T, probabilities.sum(axis=1)).T\n",
    "\n",
    "    val = np.random.choice(choice_array[fixed_j,:], p = proba_vector[fixed_j,:])\n",
    "    if val != -1:\n",
    "        already_taken.append(val)\n",
    "    new_z.append(val)\n",
    "\n",
    "print(new_z)\n",
    "\n",
    "# probabilities = np.concatenate([probabilities, proba_no_link], axis=1)\n",
    "\n",
    "#     choice_array = np.arange(file_A.shape[0])\n",
    "#     choice_array = np.append(choice_array, -1)\n",
    "#     choice_array = np.tile(choice_array, file_B.shape[0]).reshape(file_B.shape[0], file_A.shape[0]+1)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  -1,    3,    7, ..., 2797, 2798, 2799]),\n",
       " array([816,   1,   1, ...,   1,   1,   2]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(new_z), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_no_link = (file_A.shape[0] - n_AB_) * (file_B.shape[0] - n_AB_ - 1 + beta_pi) / (n_AB_ + alpha_pi)\n",
    "probabilities = np.concatenate([probabilities, proba_no_link], axis = 1)\n",
    "print(\"proba shape\", probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 1)\n"
     ]
    }
   ],
   "source": [
    "print(proba_no_link.reshape(-1,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_array = np.tile(choice_array, file_B.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4402200,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.000e+00  1.579e+03 -1.000e+00 ... -1.000e+00 -1.000e+00  2.799e+03]\n",
      "              name       family_name country  birth_year  was_assigned_female  \\\n",
      "0        Francesco            Leggio      NL        1941                    0   \n",
      "1        Francesca           Melillo      IT        1957                    1   \n",
      "2            Данис        Уразбахтин      RU        1976                    0   \n",
      "3           Tobias        Schlothane      DE        1959                    0   \n",
      "4           Joanna         Kaczmarek      PL        2019                    1   \n",
      "..             ...               ...     ...         ...                  ...   \n",
      "815           Nika           Cheshko      RU        1998                    1   \n",
      "816         Brahim            Chakib      BE        1959                    0   \n",
      "817        Наталия         Леонтьева      RU        1961                    1   \n",
      "818  Galata Closep             Urena      ES        1954                    1   \n",
      "819        Nicolay  Dimitrov Vasilev      ES        1954                    0   \n",
      "\n",
      "     X1        X2        X3        X4        X5  treatment          Y  \\\n",
      "0    79  3.170343 -0.448613  1.335413  1.198864          0 -11.958012   \n",
      "1    63  2.422049 -0.052444  1.190374  0.419838          0  -9.937546   \n",
      "2    44  2.050368  0.738659  0.350138  0.310526          0  -7.168358   \n",
      "3    61  3.051417  0.854797 -0.031462  2.371182          0  -4.159073   \n",
      "4     1  2.010973 -0.139847  0.297890  2.438343          1   2.769476   \n",
      "..   ..       ...       ...       ...       ...        ...        ...   \n",
      "815  22  2.203196 -0.945494  1.236170  0.188317          0 -11.497823   \n",
      "816  61  3.302928 -0.190227  2.340707  2.738926          0  -8.907173   \n",
      "817  59  0.422982 -0.377180  4.405308  1.486148          0  -9.921143   \n",
      "818  66  2.927340 -0.549391  0.453513 -0.243677          0 -13.055622   \n",
      "819  66  0.479733  0.639616  0.097347  0.424534          0  -6.314630   \n",
      "\n",
      "     intercept  propensity_score  \n",
      "0            1          0.000269  \n",
      "1            1          0.002504  \n",
      "2            1          0.013782  \n",
      "3            1          0.000369  \n",
      "4            1          0.387892  \n",
      "..         ...               ...  \n",
      "815          1          0.335227  \n",
      "816          1          0.001029  \n",
      "817          1          0.006932  \n",
      "818          1          0.002520  \n",
      "819          1          0.000850  \n",
      "\n",
      "[820 rows x 14 columns]\n",
      "[0.95 0.95 0.95 0.95]\n",
      "[3.81655844e-04 5.01122078e-01 1.09344318e-01 1.44659416e-01]\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0.6651491814342458\n",
      "0.9524076903983539\n",
      "0.01607863302089355\n",
      "3.1393585352501603\n",
      "0.9556281266613694\n",
      "1.5154764262631084\n"
     ]
    }
   ],
   "source": [
    "# TODO revoir parametres initiaux!!!\n",
    "# \n",
    "# \n",
    "print(z_k[-1])\n",
    "\n",
    "print(linked_records_k[-1])\n",
    "\n",
    "print(theta_m_k[-1])\n",
    "\n",
    "print(theta_u_k[-1])\n",
    "\n",
    "print(alpha_pi_k[-1])\n",
    "print(beta_pi_k[-1])\n",
    "\n",
    "print(a_sigma_k[-1])\n",
    "print(b_sigma_k [-1])\n",
    "\n",
    "print(a_sigma2_k[-1])\n",
    "print(b_sigma2_k[-1])\n",
    "\n",
    "print(beta0_k[-1])\n",
    "print(beta1_k[-1])\n",
    "print(alpha_k[-1])\n",
    "print(sigma_square_k[-1])\n",
    "\n",
    "print(mu2_k[-1])\n",
    "print(sigma2_square_k[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update linkage z_j\n",
    "\n",
    "fixed_j = 3\n",
    "file_AB = AB.copy()\n",
    "comparison_for_j = comparison_vectors_only[file_AB.source_index_B==fixed_j].copy()\n",
    "theta_m = theta_m_k[-1]\n",
    "theta_u = theta_u_k[-1]\n",
    "mu2 = mu2_k[-1]\n",
    "sigma2_square = sigma2_square_k[-1]\n",
    "\n",
    "w1 = ( np.multiply( comparison_for_j, np.log(theta_m/theta_u) ) + np.multiply( 1-comparison_for_j, np.log((1-theta_m)/(1-theta_u)) ) ).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x152493b20>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w2_unmatched_outcome = scipy.stats.norm.pdf(file_AB[file_AB.source_index_B==fixed_j].Y, mu2, np.sqrt(sigma2_square))\n",
    "\n",
    "beta0 = beta0_k[-1]\n",
    "beta1 = beta1_k[-1]\n",
    "alpha = alpha_k[-1]\n",
    "\n",
    "data_for_j = file_AB[file_AB.source_index_B==fixed_j].copy()\n",
    "residuals = data_for_j.Y - np.array([data_for_j.intercept, data_for_j.propensity_score, data_for_j.propensity_score * data_for_j.treatment]).T @ np.array([beta0, beta1, alpha]).T\n",
    "residuals_variance = residuals.T @ residuals / (len(residuals) - (3+1))\n",
    "\n",
    "w2_matched_outcome = scipy.stats.norm.pdf(residuals, 0, np.sqrt(residuals_variance))\n",
    "\n",
    "w2 = np.log(w2_matched_outcome/w2_unmatched_outcome)\n",
    "\n",
    "probabilities = np.array(np.exp(w1+w2))\n",
    "\n",
    "plt.plot(probabilities)\n",
    "\n",
    "z = z_k[-1]\n",
    "beta_pi = beta_pi_k[-1]\n",
    "alpha_pi = alpha_pi_k[-1]\n",
    "others = np.delete(z, fixed_j)\n",
    "n_AB_ = (others>=0).sum()\n",
    "file_A = A.copy()\n",
    "file_B = B.copy()\n",
    "proba_no_link = (file_A.shape[0] - n_AB_) * (file_B.shape[0] - n_AB_ - 1 + beta_pi) / (n_AB_ + alpha_pi)\n",
    "probabilities = np.append(probabilities, proba_no_link)\n",
    "\n",
    "plt.plot(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_7/32t15g3d2h54d0ct6cssb9gh0000gn/T/ipykernel_13840/261696753.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  plt.plot(np.exp(np.array(w1/w2)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1525fb730>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(w2_unmatched_outcome)\n",
    "\n",
    "plt.plot(np.array(w1))\n",
    "\n",
    "plt.plot(w2)\n",
    "\n",
    "plt.plot(w2_unmatched_outcome)\n",
    "\n",
    "plt.plot(w2_matched_outcome)\n",
    "\n",
    "plt.plot(np.log(w2_matched_outcome/w2_unmatched_outcome))\n",
    "\n",
    "plt.plot(w1 + np.log(w2_matched_outcome/w2_unmatched_outcome))\n",
    "\n",
    "plt.plot(np.exp(np.array(w1/w2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tester",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b95706f4894ee4355943f31879e0e3a76d825289e1bc7e0d16bc1dcbc4ba3b09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
