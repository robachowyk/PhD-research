{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import numpy as np\n",
    "import textdistance\n",
    "import timeit\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "from patsy import dmatrix\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_DF = 'DF_N=4401_2023-01-16.csv'\n",
    "DF = pds.read_csv(os.path.join('..', 'datasets', name_DF), delimiter = ',')\n",
    "DF = DF[~DF.duplicated()] # delete duplicates\n",
    "DF = DF.dropna() # delete NaN values\n",
    "DF['was_assigned_female'] = DF['was_assigned_female'].astype('int32') # turn was_born_female into int type (once Nan values have been removed)\n",
    "\n",
    "identifiers = {'family_name':'jaro-winkler','was_assigned_female':'strict','country':'strict','birth_year':'large'}\n",
    "covariates = ['X1','X2','X3','X4','X5']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate association\n",
    "\n",
    "$Y = -10 + a T X_2 + b \\exp^{X_4} + c X_3 X_1 + d X_5$\n",
    "\n",
    "Then the average treatment effect equals $a \\times \\mathbb E [X_2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GENERATES ASSOCIATION ##########\n",
    "\n",
    "# generate covariates\n",
    "DF['X1'] = 2020 - DF['birth_year'] # age\n",
    "DF['X2'] = np.random.normal(loc = 2.5, scale = 1, size = DF.shape[0])\n",
    "DF['X3'] = np.random.normal(loc = 0, scale = 1, size = DF.shape[0])\n",
    "DF['X4'] = np.random.normal(loc = 1, scale = 1, size = DF.shape[0])\n",
    "DF['X5'] = np.random.normal(loc = 1, scale = 1, size = DF.shape[0])\n",
    "\n",
    "# generate treatment\n",
    "DF['treatment'] = np.random.binomial(n = 1, p = 1 / ( 1 + np.exp(0.1*DF.X1 -0.2*DF.X2 +0.3*DF.X3 -0.4*DF.X4 +0.5*DF.X5) )) # probability depending on covariates\n",
    "\n",
    "# generate outcome\n",
    "residual_errors = np.random.normal(size = DF.shape[0])\n",
    "a = 5.5\n",
    "b = 0.01\n",
    "c = 0.08\n",
    "d = 0.7\n",
    "\n",
    "ate = a * 2.5\n",
    "DF['Y'] = - 10 + a*DF['treatment']*DF['X2'] + b*np.exp(DF['X4']) + c*DF['X3']*DF['X1'] + d*DF['X5'] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 2 datasets with overlap for record linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_records = DF.sample(n = 800)\n",
    "\n",
    "B = pds.concat([DF.sample(n = 1400), common_records]).drop(['Y'], axis = 1)\n",
    "B = B.reset_index(drop=True)\n",
    "\n",
    "A = pds.concat([DF.sample(n = 2000), common_records])[list(identifiers.keys())+['Y']]\n",
    "A = A.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build functions\n",
    "\n",
    "- comparison_vector\n",
    "- linking_score\n",
    "- levenshtein_similarity\n",
    "- jaro_winkler_similarity\n",
    "- strict_equality\n",
    "- large_equality\n",
    "- logit\n",
    "- minmaxscaler\n",
    "- propensity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def comparison_vector(A_record, B, identifiers):\n",
    "    \n",
    "#     \"\"\" Compare one record in A with all records in B. \n",
    "#         Return the binary comparison of the identifiers for one record in A with all records in B.\n",
    "\n",
    "#         A_record:     series of one row, \n",
    "#         B:            dataframe, \n",
    "#         identifiers:  dict: k = column name, \n",
    "#                             v = method in {'large','strict','levenshtein','jaro-winkler'}\n",
    "#     \"\"\"\n",
    "\n",
    "#     methods = {'jaro-winkler':jaro_winkler_similarity, 'levenshtein':levenshtein_similarity, 'strict':strict_equality, 'large':large_equality}\n",
    "#     comparisons = {}\n",
    "#     for linking_var in identifiers:\n",
    "#         method = methods[identifiers[linking_var]]\n",
    "#         comparisons[linking_var] = np.array(B.apply(lambda row: method(A_record[linking_var], row[linking_var]), axis=1)).reshape(-1,1)\n",
    "#     return np.concatenate(tuple(comparisons.values()), axis = 1) \n",
    "\n",
    "# def linking_score(A, B, identifiers, match, unmatch):\n",
    "        \n",
    "#     \"\"\" Compare records in A with records in B, computing all linking scores for records in A with records in B. \n",
    "#         Return the indices of records in A with the best match index for record in B.\n",
    "\n",
    "#         A:            dataframe, \n",
    "#         B:            dataframe, \n",
    "#         identifiers:  dict: k = column name, \n",
    "#                             v = method in {'large','strict','levenshtein','jaro-winkler'}\n",
    "#         match:        array of probabilities of having same linking variables when being a match,\n",
    "#         unmatch:      array of probabilities of having same linking variables (at all, among the nA x nB pairs of record).\n",
    "#     \"\"\"\n",
    "\n",
    "#     def compute_max_linking_score(A_record, B, identifiers, match, unmatch):\n",
    "#         similarities = comparison_vector(A_record, B, identifiers)\n",
    "#         if similarities.all(axis=1).sum() == 1: # there is one unique match: possible true match\n",
    "#             return B.iloc[similarities.all(axis=1),:].index[0], np.NaN\n",
    "#         else:\n",
    "#             linking_score = (np.multiply(similarities, np.log2(match/unmatch)) + np.multiply(1-similarities, np.log2((1-match)/(1-unmatch)))).sum(axis=1)\n",
    "#             return linking_score.argmax(), linking_score.max() # assign the first element of the argmax set A REVOIR\n",
    "\n",
    "#     links = A.apply(lambda row: compute_max_linking_score(row[list(identifiers.keys())], B, identifiers, match, unmatch), axis=1)\n",
    "#     idx_in_A = np.arange(A.shape[0])\n",
    "#     idx_in_B = np.array([element[0] for element in links])\n",
    "#     matching_scores = np.array([element[1] for element in links])\n",
    "#     max_score = np.nanmax(matching_scores)\n",
    "#     matching_scores = np.nan_to_num(matching_scores, nan=max_score+1) # possible true matches are given a higher score\n",
    "#     return {'A':idx_in_A, 'B':idx_in_B, 'scores':matching_scores}\n",
    "    \n",
    "def levenshtein_similarity(a,b):\n",
    "\n",
    "    \"\"\" Check that levenshtein similarity (in [0,1]) is above 0.95.\n",
    "        \n",
    "        a: string,\n",
    "        b: string \"\"\"\n",
    "\n",
    "    if 1 - textdistance.levenshtein(a, b)/max(len(a),len(b)) >= 0.95:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def jaro_winkler_similarity(a,b):\n",
    "\n",
    "    \"\"\" Check that jaro-winkler similarity (in [0,1]) is above 0.95.\n",
    "        \n",
    "        a: string,\n",
    "        b: string \"\"\"\n",
    "\n",
    "    if textdistance.jaro_winkler(a,b) >= 0.99:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def strict_equality(a,b):\n",
    "\n",
    "    \"\"\" Check that a and b values are equal.\n",
    "        \n",
    "        a: any value,\n",
    "        b: any value \"\"\"\n",
    "\n",
    "    return a==b\n",
    "\n",
    "def large_equality(a,b):\n",
    "\n",
    "    \"\"\" Check that years a and b expressed with four numbers are within the same decade.\n",
    "        \n",
    "        a: year,\n",
    "        b: year \"\"\"\n",
    "\n",
    "    return str(a)[:-1]==str(b)[:-1]\n",
    "\n",
    "def logit(p):\n",
    "    return np.log(p/(1-p))\n",
    "\n",
    "def minmaxscaler(X):\n",
    "    return (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "    \n",
    "def propensity_score(DF, covariates, scaler, convert_to_logit):\n",
    "    \n",
    "    \"\"\" Compute propensity score estimates: the probability (logistic regression) that an observation is treated or not conditioned on some covariates.\n",
    "        These estimates are built conditionaly on covariates passed using a logit after transformation by scaler (when one is specified).\n",
    "        Estimated probabilities can be converted into logit (convert_to_logit parameter).\n",
    "\n",
    "        DF:                dataframe,\n",
    "        covariates:        list of strings for covariates variable in DF,\n",
    "        scaler:            sklearn.preprocessing function scaler for exemple,\n",
    "        convert_to_logit:  boolean for converting probabilities to logit when building the propensity score estimates based on a logistic regression\n",
    "    \"\"\"\n",
    "    exog = covariates.copy()\n",
    "    if scaler != None:\n",
    "        DF[exog] = scaler(DF[exog])\n",
    "    if 'intercept' not in DF.columns:\n",
    "        DF['intercept'] = 1\n",
    "    exog.append('intercept')\n",
    "    model = sm.Logit(DF.treatment, DF[exog]).fit()\n",
    "    predictions = model.predict(DF[exog])\n",
    "    if convert_to_logit:\n",
    "        return logit(predictions)\n",
    "    else: \n",
    "        return predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate Guha's work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate initial parameters\n",
    "\n",
    "- z\n",
    "- linkage match\n",
    "- linkage unmatch\n",
    "- outcome match\n",
    "- outcome unmatch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build initial linkage parameter\n",
    "\n",
    "- z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_0\n",
    "\n",
    "# for each index (in A) \n",
    "# z = index of the record linked in B or if not, n_A + index\n",
    "\n",
    "# z = np.arange(n_A)\n",
    "# matchings = linking_score(A, B, identifiers, match, unmatch)\n",
    "# best_score = np.max(matchings['scores']) \n",
    "# best_matches = matchings['scores'] >= best_score\n",
    "# z[best_matches] = matchings['B'][best_matches]\n",
    "# z[~best_matches] = z[~best_matches] + n_A\n",
    "# print(f\"# common records:  {common_records.shape[0]}\\n# best matches:    {len(z[z<=n_A])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build initial set of linked records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_in_A = np.nonzero(z[z <= n_A])[0]\n",
    "# idx_in_B = z[z <= n_A]\n",
    "# from_A = A.iloc[idx_in_A,:].reset_index(drop=True)\n",
    "# from_B = B.iloc[idx_in_B,:].reset_index(drop=True)\n",
    "# linked_records = pds.concat([from_A, from_B.Y], axis=1)\n",
    "# linked_records['propensity_score'] = propensity_score(linked_records, covariates, None, False)\n",
    "# print(f\"\\n# common records:  {common_records.shape[0]}\\n# linked records:  {linked_records.shape[0]}\\n\")\n",
    "# linked_records.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build parameters for match and unmatch distr. of linkage variables and a table of the comparison btw $A$ and $B$ records\n",
    "\n",
    "- linkage match\n",
    "- linkage unmatch\n",
    "- table of similarities among records???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = np.arange(A.shape[0])\n",
    "# z[data[\"source_index_A\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create all possible pairs of records in $AB$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_name_x</th>\n",
       "      <th>was_assigned_female_x</th>\n",
       "      <th>country_x</th>\n",
       "      <th>birth_year_x</th>\n",
       "      <th>family_name_y</th>\n",
       "      <th>was_assigned_female_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>birth_year_y</th>\n",
       "      <th>source_index_B</th>\n",
       "      <th>source_index_A</th>\n",
       "      <th>family_name_comparison</th>\n",
       "      <th>was_assigned_female_comparison</th>\n",
       "      <th>country_comparison</th>\n",
       "      <th>birth_year_comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hofer</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>Hols</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hofer</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kral</td>\n",
       "      <td>1</td>\n",
       "      <td>AT</td>\n",
       "      <td>1952</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hofer</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>Nazari</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hofer</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>Uter</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hofer</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>Иванова</td>\n",
       "      <td>1</td>\n",
       "      <td>RU</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159995</th>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>Воронцова</td>\n",
       "      <td>1</td>\n",
       "      <td>RU</td>\n",
       "      <td>1976</td>\n",
       "      <td>2199</td>\n",
       "      <td>2795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159996</th>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>Arjona Gomez</td>\n",
       "      <td>1</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>2199</td>\n",
       "      <td>2796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159997</th>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>Ådland</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>2014</td>\n",
       "      <td>2199</td>\n",
       "      <td>2797</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159998</th>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>Губатюк</td>\n",
       "      <td>1</td>\n",
       "      <td>RU</td>\n",
       "      <td>1955</td>\n",
       "      <td>2199</td>\n",
       "      <td>2798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159999</th>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>2199</td>\n",
       "      <td>2799</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6160000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        family_name_x  was_assigned_female_x country_x  birth_year_x  \\\n",
       "0               Hofer                      0        CH          2008   \n",
       "1               Hofer                      0        CH          2008   \n",
       "2               Hofer                      0        CH          2008   \n",
       "3               Hofer                      0        CH          2008   \n",
       "4               Hofer                      0        CH          2008   \n",
       "...               ...                    ...       ...           ...   \n",
       "6159995        Marchi                      0        IT          1948   \n",
       "6159996        Marchi                      0        IT          1948   \n",
       "6159997        Marchi                      0        IT          1948   \n",
       "6159998        Marchi                      0        IT          1948   \n",
       "6159999        Marchi                      0        IT          1948   \n",
       "\n",
       "        family_name_y  was_assigned_female_y country_y  birth_year_y  \\\n",
       "0                Hols                      0        IT          2013   \n",
       "1                Kral                      1        AT          1952   \n",
       "2              Nazari                      0        DE          1995   \n",
       "3                Uter                      0        DE          2003   \n",
       "4             Иванова                      1        RU          1998   \n",
       "...               ...                    ...       ...           ...   \n",
       "6159995     Воронцова                      1        RU          1976   \n",
       "6159996  Arjona Gomez                      1        ES          1981   \n",
       "6159997        Ådland                      1        NO          2014   \n",
       "6159998       Губатюк                      1        RU          1955   \n",
       "6159999        Marchi                      0        IT          1948   \n",
       "\n",
       "         source_index_B  source_index_A  family_name_comparison  \\\n",
       "0                     0               0                       0   \n",
       "1                     0               1                       0   \n",
       "2                     0               2                       0   \n",
       "3                     0               3                       0   \n",
       "4                     0               4                       0   \n",
       "...                 ...             ...                     ...   \n",
       "6159995            2199            2795                       0   \n",
       "6159996            2199            2796                       0   \n",
       "6159997            2199            2797                       0   \n",
       "6159998            2199            2798                       0   \n",
       "6159999            2199            2799                       1   \n",
       "\n",
       "         was_assigned_female_comparison  country_comparison  \\\n",
       "0                                     1                   0   \n",
       "1                                     0                   0   \n",
       "2                                     1                   0   \n",
       "3                                     1                   0   \n",
       "4                                     0                   0   \n",
       "...                                 ...                 ...   \n",
       "6159995                               0                   0   \n",
       "6159996                               0                   0   \n",
       "6159997                               0                   0   \n",
       "6159998                               0                   0   \n",
       "6159999                               1                   1   \n",
       "\n",
       "         birth_year_comparison  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            1  \n",
       "4                            0  \n",
       "...                        ...  \n",
       "6159995                      0  \n",
       "6159996                      0  \n",
       "6159997                      0  \n",
       "6159998                      0  \n",
       "6159999                      1  \n",
       "\n",
       "[6160000 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AB = B[identifiers.keys()].merge(A[identifiers.keys()], how='cross')\n",
    "\n",
    "AB[\"source_index_B\"] = np.repeat(B.index, A.shape[0])\n",
    "AB[\"source_index_A\"] = np.tile(A.index, B.shape[0])\n",
    "\n",
    "methods = {'jaro-winkler':jaro_winkler_similarity, 'levenshtein':levenshtein_similarity, 'strict':strict_equality, 'large':large_equality}\n",
    "\n",
    "for linking_var in identifiers.keys():\n",
    "    method = methods[identifiers[linking_var]]\n",
    "    df = AB.filter(regex=linking_var)\n",
    "    AB[linking_var+\"_comparison\"] = np.array([method(a, b) for a,b in zip(df.iloc[:,0], df.iloc[:,1])]).astype(int).reshape(-1,1)\n",
    "\n",
    "AB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only \"exact\" matches (where all comparisons $= 1$ and enforce 1-2-1 matching removing all duplicata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_name_x</th>\n",
       "      <th>was_assigned_female_x</th>\n",
       "      <th>country_x</th>\n",
       "      <th>birth_year_x</th>\n",
       "      <th>family_name_y</th>\n",
       "      <th>was_assigned_female_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>birth_year_y</th>\n",
       "      <th>source_index_B</th>\n",
       "      <th>source_index_A</th>\n",
       "      <th>family_name_comparison</th>\n",
       "      <th>was_assigned_female_comparison</th>\n",
       "      <th>country_comparison</th>\n",
       "      <th>birth_year_comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Hofer</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>Hofer</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9473</th>\n",
       "      <td>Madjidov</td>\n",
       "      <td>0</td>\n",
       "      <td>RU</td>\n",
       "      <td>1976</td>\n",
       "      <td>Madjidov</td>\n",
       "      <td>0</td>\n",
       "      <td>RU</td>\n",
       "      <td>1976</td>\n",
       "      <td>3</td>\n",
       "      <td>1073</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14872</th>\n",
       "      <td>Thomassen</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2014</td>\n",
       "      <td>Thomassen</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31559</th>\n",
       "      <td>Кузнецов</td>\n",
       "      <td>0</td>\n",
       "      <td>RU</td>\n",
       "      <td>1955</td>\n",
       "      <td>Кузнецов</td>\n",
       "      <td>0</td>\n",
       "      <td>RU</td>\n",
       "      <td>1955</td>\n",
       "      <td>11</td>\n",
       "      <td>759</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37186</th>\n",
       "      <td>Sweet</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>1982</td>\n",
       "      <td>Sweet</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>1982</td>\n",
       "      <td>13</td>\n",
       "      <td>786</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126387</th>\n",
       "      <td>Vanderhoeden</td>\n",
       "      <td>1</td>\n",
       "      <td>BE</td>\n",
       "      <td>2002</td>\n",
       "      <td>Vanderhoeden</td>\n",
       "      <td>1</td>\n",
       "      <td>BE</td>\n",
       "      <td>2002</td>\n",
       "      <td>2187</td>\n",
       "      <td>2787</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6137591</th>\n",
       "      <td>Kopotilov</td>\n",
       "      <td>0</td>\n",
       "      <td>RU</td>\n",
       "      <td>1961</td>\n",
       "      <td>Kopotilov</td>\n",
       "      <td>0</td>\n",
       "      <td>RU</td>\n",
       "      <td>1961</td>\n",
       "      <td>2191</td>\n",
       "      <td>2791</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140392</th>\n",
       "      <td>Мур</td>\n",
       "      <td>1</td>\n",
       "      <td>RU</td>\n",
       "      <td>1955</td>\n",
       "      <td>Мур</td>\n",
       "      <td>1</td>\n",
       "      <td>RU</td>\n",
       "      <td>1955</td>\n",
       "      <td>2192</td>\n",
       "      <td>2792</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151596</th>\n",
       "      <td>Arjona Gomez</td>\n",
       "      <td>1</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>Arjona Gomez</td>\n",
       "      <td>1</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>2196</td>\n",
       "      <td>2796</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159999</th>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>2199</td>\n",
       "      <td>2799</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        family_name_x  was_assigned_female_x country_x  birth_year_x  \\\n",
       "670             Hofer                      0        CH          2008   \n",
       "9473         Madjidov                      0        RU          1976   \n",
       "14872       Thomassen                      0        NO          2014   \n",
       "31559        Кузнецов                      0        RU          1955   \n",
       "37186           Sweet                      0        GB          1982   \n",
       "...               ...                    ...       ...           ...   \n",
       "6126387  Vanderhoeden                      1        BE          2002   \n",
       "6137591     Kopotilov                      0        RU          1961   \n",
       "6140392           Мур                      1        RU          1955   \n",
       "6151596  Arjona Gomez                      1        ES          1981   \n",
       "6159999        Marchi                      0        IT          1948   \n",
       "\n",
       "        family_name_y  was_assigned_female_y country_y  birth_year_y  \\\n",
       "670             Hofer                      0        CH          2008   \n",
       "9473         Madjidov                      0        RU          1976   \n",
       "14872       Thomassen                      0        NO          2014   \n",
       "31559        Кузнецов                      0        RU          1955   \n",
       "37186           Sweet                      0        GB          1982   \n",
       "...               ...                    ...       ...           ...   \n",
       "6126387  Vanderhoeden                      1        BE          2002   \n",
       "6137591     Kopotilov                      0        RU          1961   \n",
       "6140392           Мур                      1        RU          1955   \n",
       "6151596  Arjona Gomez                      1        ES          1981   \n",
       "6159999        Marchi                      0        IT          1948   \n",
       "\n",
       "         source_index_B  source_index_A  family_name_comparison  \\\n",
       "670                   0             670                       1   \n",
       "9473                  3            1073                       1   \n",
       "14872                 5             872                       1   \n",
       "31559                11             759                       1   \n",
       "37186                13             786                       1   \n",
       "...                 ...             ...                     ...   \n",
       "6126387            2187            2787                       1   \n",
       "6137591            2191            2791                       1   \n",
       "6140392            2192            2792                       1   \n",
       "6151596            2196            2796                       1   \n",
       "6159999            2199            2799                       1   \n",
       "\n",
       "         was_assigned_female_comparison  country_comparison  \\\n",
       "670                                   1                   1   \n",
       "9473                                  1                   1   \n",
       "14872                                 1                   1   \n",
       "31559                                 1                   1   \n",
       "37186                                 1                   1   \n",
       "...                                 ...                 ...   \n",
       "6126387                               1                   1   \n",
       "6137591                               1                   1   \n",
       "6140392                               1                   1   \n",
       "6151596                               1                   1   \n",
       "6159999                               1                   1   \n",
       "\n",
       "         birth_year_comparison  \n",
       "670                          1  \n",
       "9473                         1  \n",
       "14872                        1  \n",
       "31559                        1  \n",
       "37186                        1  \n",
       "...                        ...  \n",
       "6126387                      1  \n",
       "6137591                      1  \n",
       "6140392                      1  \n",
       "6151596                      1  \n",
       "6159999                      1  \n",
       "\n",
       "[810 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = AB[AB.filter(regex=\"comparison\").all(axis=1)]\n",
    "comparisons_exact_matched_records = data[ (~data.filter(regex=\"_x\").duplicated(keep=False)) & (~data.filter(regex=\"_y\").duplicated(keep=False)) ]\n",
    "comparisons_exact_matched_records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute linking score over all pairs of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_name_x</th>\n",
       "      <th>was_assigned_female_x</th>\n",
       "      <th>country_x</th>\n",
       "      <th>birth_year_x</th>\n",
       "      <th>family_name_y</th>\n",
       "      <th>was_assigned_female_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>birth_year_y</th>\n",
       "      <th>source_index_B</th>\n",
       "      <th>source_index_A</th>\n",
       "      <th>family_name_comparison</th>\n",
       "      <th>was_assigned_female_comparison</th>\n",
       "      <th>country_comparison</th>\n",
       "      <th>birth_year_comparison</th>\n",
       "      <th>linking_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hofer</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>Hols</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.639935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hofer</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kral</td>\n",
       "      <td>1</td>\n",
       "      <td>AT</td>\n",
       "      <td>1952</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.886268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hofer</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>Nazari</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.639935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hofer</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>Uter</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.867929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hofer</td>\n",
       "      <td>0</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>Иванова</td>\n",
       "      <td>1</td>\n",
       "      <td>RU</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.886268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159995</th>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>Воронцова</td>\n",
       "      <td>1</td>\n",
       "      <td>RU</td>\n",
       "      <td>1976</td>\n",
       "      <td>2199</td>\n",
       "      <td>2795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.886268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159996</th>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>Arjona Gomez</td>\n",
       "      <td>1</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>2199</td>\n",
       "      <td>2796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.886268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159997</th>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>Ådland</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>2014</td>\n",
       "      <td>2199</td>\n",
       "      <td>2797</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.886268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159998</th>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>Губатюк</td>\n",
       "      <td>1</td>\n",
       "      <td>RU</td>\n",
       "      <td>1955</td>\n",
       "      <td>2199</td>\n",
       "      <td>2798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.886268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159999</th>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>Marchi</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>2199</td>\n",
       "      <td>2799</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.981576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6160000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        family_name_x  was_assigned_female_x country_x  birth_year_x  \\\n",
       "0               Hofer                      0        CH          2008   \n",
       "1               Hofer                      0        CH          2008   \n",
       "2               Hofer                      0        CH          2008   \n",
       "3               Hofer                      0        CH          2008   \n",
       "4               Hofer                      0        CH          2008   \n",
       "...               ...                    ...       ...           ...   \n",
       "6159995        Marchi                      0        IT          1948   \n",
       "6159996        Marchi                      0        IT          1948   \n",
       "6159997        Marchi                      0        IT          1948   \n",
       "6159998        Marchi                      0        IT          1948   \n",
       "6159999        Marchi                      0        IT          1948   \n",
       "\n",
       "        family_name_y  was_assigned_female_y country_y  birth_year_y  \\\n",
       "0                Hols                      0        IT          2013   \n",
       "1                Kral                      1        AT          1952   \n",
       "2              Nazari                      0        DE          1995   \n",
       "3                Uter                      0        DE          2003   \n",
       "4             Иванова                      1        RU          1998   \n",
       "...               ...                    ...       ...           ...   \n",
       "6159995     Воронцова                      1        RU          1976   \n",
       "6159996  Arjona Gomez                      1        ES          1981   \n",
       "6159997        Ådland                      1        NO          2014   \n",
       "6159998       Губатюк                      1        RU          1955   \n",
       "6159999        Marchi                      0        IT          1948   \n",
       "\n",
       "         source_index_B  source_index_A  family_name_comparison  \\\n",
       "0                     0               0                       0   \n",
       "1                     0               1                       0   \n",
       "2                     0               2                       0   \n",
       "3                     0               3                       0   \n",
       "4                     0               4                       0   \n",
       "...                 ...             ...                     ...   \n",
       "6159995            2199            2795                       0   \n",
       "6159996            2199            2796                       0   \n",
       "6159997            2199            2797                       0   \n",
       "6159998            2199            2798                       0   \n",
       "6159999            2199            2799                       1   \n",
       "\n",
       "         was_assigned_female_comparison  country_comparison  \\\n",
       "0                                     1                   0   \n",
       "1                                     0                   0   \n",
       "2                                     1                   0   \n",
       "3                                     1                   0   \n",
       "4                                     0                   0   \n",
       "...                                 ...                 ...   \n",
       "6159995                               0                   0   \n",
       "6159996                               0                   0   \n",
       "6159997                               0                   0   \n",
       "6159998                               0                   0   \n",
       "6159999                               1                   1   \n",
       "\n",
       "         birth_year_comparison  linking_score  \n",
       "0                            0     -11.639935  \n",
       "1                            0     -15.886268  \n",
       "2                            0     -11.639935  \n",
       "3                            1      -4.867929  \n",
       "4                            0     -15.886268  \n",
       "...                        ...            ...  \n",
       "6159995                      0     -15.886268  \n",
       "6159996                      0     -15.886268  \n",
       "6159997                      0     -15.886268  \n",
       "6159998                      0     -15.886268  \n",
       "6159999                      1      17.981576  \n",
       "\n",
       "[6160000 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons = AB.filter(regex=\"comparison\")\n",
    "\n",
    "unmatch = comparisons.sum(axis=0) / len(comparisons) # probability of having same linking var (at all)\n",
    "\n",
    "match = np.repeat(0.95, len(identifiers.keys())) # probability of having same linking var when being matches\n",
    "\n",
    "AB[\"linking_score\"] = (np.multiply(comparisons, np.log2(match/unmatch)) + np.multiply(1-comparisons, np.log2((1-match)/(1-unmatch)))).sum(axis=1)\n",
    "\n",
    "AB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each record in $A$ we would like to find the best match in $B$ (we remove records from $A$ and from $B$ that matches more than once)\n",
    "\n",
    "Produce the linkage variable $$z_i = \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        j & \\text{if } \\{i,j\\} \\text{ are matched} \\\\\n",
    "        i + n_B & \\text{otherwise.}\n",
    "    \\end{array}\n",
    "\\right.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.240693\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>family_name</th>\n",
       "      <th>country</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>was_assigned_female</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>treatment</th>\n",
       "      <th>Y</th>\n",
       "      <th>intercept</th>\n",
       "      <th>propensity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stefan</td>\n",
       "      <td>Hofer</td>\n",
       "      <td>CH</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2.690921</td>\n",
       "      <td>-0.114563</td>\n",
       "      <td>1.308119</td>\n",
       "      <td>1.468779</td>\n",
       "      <td>1</td>\n",
       "      <td>5.755224</td>\n",
       "      <td>1</td>\n",
       "      <td>0.342631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mykhammad</td>\n",
       "      <td>Madjidov</td>\n",
       "      <td>RU</td>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3.873064</td>\n",
       "      <td>-0.522982</td>\n",
       "      <td>0.927945</td>\n",
       "      <td>0.507575</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.460300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunnar Wessel</td>\n",
       "      <td>Thomassen</td>\n",
       "      <td>NO</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.155654</td>\n",
       "      <td>-0.359078</td>\n",
       "      <td>1.023478</td>\n",
       "      <td>3.098727</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.975420</td>\n",
       "      <td>1</td>\n",
       "      <td>0.299145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Евгений</td>\n",
       "      <td>Кузнецов</td>\n",
       "      <td>RU</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>1.188225</td>\n",
       "      <td>-0.571403</td>\n",
       "      <td>1.572769</td>\n",
       "      <td>2.455389</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.204325</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aj</td>\n",
       "      <td>Sweet</td>\n",
       "      <td>GB</td>\n",
       "      <td>1982</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.576695</td>\n",
       "      <td>1.887227</td>\n",
       "      <td>-0.312163</td>\n",
       "      <td>1.189375</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.422948</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>Raymonde</td>\n",
       "      <td>Vanderhoeden</td>\n",
       "      <td>BE</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1.858974</td>\n",
       "      <td>1.078054</td>\n",
       "      <td>0.233022</td>\n",
       "      <td>1.575420</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.332183</td>\n",
       "      <td>1</td>\n",
       "      <td>0.129250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>Anton</td>\n",
       "      <td>Kopotilov</td>\n",
       "      <td>RU</td>\n",
       "      <td>1961</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>3.169091</td>\n",
       "      <td>-1.398690</td>\n",
       "      <td>0.716948</td>\n",
       "      <td>-0.226947</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.740199</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>Скромница</td>\n",
       "      <td>Мур</td>\n",
       "      <td>RU</td>\n",
       "      <td>1955</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>2.314127</td>\n",
       "      <td>1.101916</td>\n",
       "      <td>2.095628</td>\n",
       "      <td>0.905180</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.555105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>Noelia</td>\n",
       "      <td>Arjona Gomez</td>\n",
       "      <td>ES</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2.766746</td>\n",
       "      <td>-0.586073</td>\n",
       "      <td>1.703235</td>\n",
       "      <td>0.583568</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.365133</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Giulio</td>\n",
       "      <td>Marchi</td>\n",
       "      <td>IT</td>\n",
       "      <td>1948</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2.884375</td>\n",
       "      <td>1.324146</td>\n",
       "      <td>2.933438</td>\n",
       "      <td>-0.314864</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.405401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name   family_name country  birth_year  was_assigned_female  X1  \\\n",
       "0           Stefan         Hofer      CH        2008                    0  12   \n",
       "1        Mykhammad      Madjidov      RU        1976                    0  44   \n",
       "2    Gunnar Wessel     Thomassen      NO        2014                    0   6   \n",
       "3          Евгений      Кузнецов      RU        1955                    0  65   \n",
       "4               Aj         Sweet      GB        1982                    0  38   \n",
       "..             ...           ...     ...         ...                  ...  ..   \n",
       "805       Raymonde  Vanderhoeden      BE        2002                    1  18   \n",
       "806          Anton     Kopotilov      RU        1961                    0  59   \n",
       "807      Скромница           Мур      RU        1955                    1  65   \n",
       "808         Noelia  Arjona Gomez      ES        1981                    1  39   \n",
       "809         Giulio        Marchi      IT        1948                    0  72   \n",
       "\n",
       "           X2        X3        X4        X5  treatment          Y  intercept  \\\n",
       "0    2.690921 -0.114563  1.308119  1.468779          1   5.755224          1   \n",
       "1    3.873064 -0.522982  0.927945  0.507575          0 -11.460300          1   \n",
       "2    2.155654 -0.359078  1.023478  3.098727          0  -7.975420          1   \n",
       "3    1.188225 -0.571403  1.572769  2.455389          0 -11.204325          1   \n",
       "4    0.576695  1.887227 -0.312163  1.189375          0  -3.422948          1   \n",
       "..        ...       ...       ...       ...        ...        ...        ...   \n",
       "805  1.858974  1.078054  0.233022  1.575420          0  -7.332183          1   \n",
       "806  3.169091 -1.398690  0.716948 -0.226947          0 -16.740199          1   \n",
       "807  2.314127  1.101916  2.095628  0.905180          0  -3.555105          1   \n",
       "808  2.766746 -0.586073  1.703235  0.583568          0 -11.365133          1   \n",
       "809  2.884375  1.324146  2.933438 -0.314864          0  -2.405401          1   \n",
       "\n",
       "     propensity_score  \n",
       "0            0.342631  \n",
       "1            0.030170  \n",
       "2            0.299145  \n",
       "3            0.001194  \n",
       "4            0.013648  \n",
       "..                ...  \n",
       "805          0.129250  \n",
       "806          0.008720  \n",
       "807          0.002430  \n",
       "808          0.051485  \n",
       "809          0.002590  \n",
       "\n",
       "[810 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = AB.linking_score.max()\n",
    "data = AB[AB.linking_score==score]\n",
    "\n",
    "# we consider 1-2-1 matches in z\n",
    "data_link = data[ (~data.source_index_A.duplicated(keep=False)) & (~data.source_index_B.duplicated(keep=False)) ]\n",
    "z = -np.ones(B.shape[0])\n",
    "z[data_link.source_index_B] = data_link.source_index_A\n",
    "\n",
    "data_nolink = AB[AB.linking_score!=score]\n",
    "# build comparisons, pattern and count for linked records:\n",
    "comparisons_match = data_link.filter(regex=\"comparison\")\n",
    "pattern_match, count_match = np.unique(comparisons_match, return_counts=True, axis=0)\n",
    "\n",
    "# build comparisons, pattern and count for non linked records (from A):\n",
    "comparisons_unmatch = data_nolink.filter(regex=\"comparison\")\n",
    "pattern_unmatch, count_unmatch = np.unique(comparisons_unmatch, return_counts=True, axis=0)\n",
    "\n",
    "from_A = A.iloc[data_link.source_index_A,:].reset_index(drop=True)\n",
    "from_B = B.iloc[data_link.source_index_B,:].reset_index(drop=True)\n",
    "linked_records = pds.concat([from_B, from_A.Y], axis=1)\n",
    "linked_records['propensity_score'] = propensity_score(linked_records, covariates, None, False)\n",
    "linked_records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First element in the likelihood: conditional outcome distribution for matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  810\n",
      "Model:                            GLM   Df Residuals:                      808\n",
      "Model Family:                Gaussian   Df Model:                            1\n",
      "Link Function:               identity   Scale:                          69.452\n",
      "Method:                          IRLS   Log-Likelihood:                -2865.8\n",
      "Date:                Tue, 31 Jan 2023   Deviance:                       56117.\n",
      "Time:                        20:34:42   Pearson chi2:                 5.61e+04\n",
      "No. Iterations:                     3   Pseudo R-squ. (CS):            -0.5790\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            33.1088      2.322     14.259      0.000      28.558      37.660\n",
      "x2           -24.9600      1.725    -14.470      0.000     -28.341     -21.579\n",
      "==============================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2865.8005608669273"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.array(linked_records.Y)\n",
    "\n",
    "X = np.array([linked_records.propensity_score*linked_records.treatment, linked_records.propensity_score])\n",
    "X = sm.add_constant(X)\n",
    "X = X.T\n",
    "\n",
    "model = sm.GLM(Y,X)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "residuals = Y - X @ results.params\n",
    "\n",
    "estimated_variance = residuals.T @ residuals / (len(residuals) - (X.shape[1]+1))\n",
    "\n",
    "np.log(scipy.stats.norm.pdf(residuals, 0, np.sqrt(estimated_variance))).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second element in the likelihood: conditional outcome distribution for non matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3507.93472520142"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log likelihood 2\n",
    "\n",
    "a_sigma2 = 1\n",
    "b_sigma2 = 1\n",
    "mu2 = scipy.stats.norm.rvs(0, 1)\n",
    "sigma2_square = scipy.stats.invgauss.rvs(a_sigma2, b_sigma2)\n",
    "\n",
    "Y = scipy.stats.norm.rvs(mu2, np.sqrt(sigma2_square), size = A.shape[0]-linked_records.shape[0])\n",
    "\n",
    "np.log(scipy.stats.norm.pdf(Y, mu2, np.sqrt(sigma2_square))).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third element in the likelihood: linkage distribution for matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-166.1902738156639"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# likelihood 3\n",
    "\n",
    "((pattern_match @ np.log(match) + (1-pattern_match) @ np.log(1-match)) * count_match).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth element in the likelihood: linkage distribution for unmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8987576.199955655"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# likelihood 4\n",
    "\n",
    "((pattern_unmatch @ np.log(unmatch) + (1-pattern_unmatch) @ np.log(1-unmatch)) * count_unmatch).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTCOME MODEL SPLINE REGRESSION ????????????????????????????????????????????????????\n",
    "\n",
    "# N = linked_records.shape[0]\n",
    "\n",
    "# s = 10\n",
    "# m = 20\n",
    "\n",
    "# beta_0 = scipy.stats.norm.rvs(0, 1, size=N)\n",
    "\n",
    "# betas_s = scipy.stats.norm.rvs(0, 1, size=(N,s))\n",
    "\n",
    "# gammas_s = scipy.stats.norm.rvs(0, 1, size=(N,s))\n",
    "\n",
    "# a_sigma = 1\n",
    "# b_sigma = 1\n",
    "# sigma_square = scipy.stats.invgauss.rvs(a_sigma, b_sigma)\n",
    "\n",
    "# knots = scipy.stats.uniform.rvs(0, 1, size=m) # remain unchanged\n",
    "# knots.sort()\n",
    "\n",
    "# r1 = 1\n",
    "# delta1 = 1\n",
    "# lambda1_square = scipy.stats.gamma.rvs(r1, delta1)\n",
    "# tau1_m_square = scipy.stats.expon.rvs(np.sqrt(lambda1_square), size=(N,m))\n",
    "# betas_s_m = scipy.stats.norm.rvs(0, np.sqrt(sigma_square*tau1_m_square), size=(N,m))\n",
    "\n",
    "# r2 = 1\n",
    "# delta2 = 1\n",
    "# lambda2_square = scipy.stats.gamma.rvs(r2, delta2)\n",
    "# tau2_m_square = scipy.stats.expon.rvs(np.sqrt(lambda2_square), size=(N,m))\n",
    "# gammas_s_m = scipy.stats.norm.rvs(0, np.sqrt(sigma_square*tau2_m_square), size=(N,m))\n",
    "\n",
    "# # for each record in linked_records: we build its outcome based on a regression splines\n",
    "# outcome_distr_match = beta_0 + ((betas_s+(np.tile(linked_records.treatment, (s,1)).T)*gammas_s) * (np.tile(linked_records.propensity_score, (s,1)).T)**np.arange(1,s+1)).sum(axis=1) + ((betas_s_m+(np.tile(linked_records.treatment, (m,1)).T)*gammas_s_m) * np.maximum(0,(np.tile(linked_records.propensity_score, (m,1)).T - knots))**np.arange(1,m+1)).sum(axis=1) + scipy.stats.norm.rvs(0, 1, size=N)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METROPOLIS HASTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISATION\n",
    "\n",
    "z_k = [z.copy()]\n",
    "\n",
    "linked_records_k = [linked_records.copy()]\n",
    "\n",
    "theta_m_k = [match.copy()]\n",
    "\n",
    "theta_u_k = [unmatch.copy()]\n",
    "\n",
    "alpha_pi_k = [1]\n",
    "beta_pi_k = [1]\n",
    "\n",
    "a_sigma_k = [1]\n",
    "b_sigma_k = [1]\n",
    "\n",
    "a_sigma2_k = [1]\n",
    "b_sigma2_k = [1]\n",
    "\n",
    "beta0_k = [scipy.stats.norm.rvs(0,1)]\n",
    "beta1_k = [scipy.stats.norm.rvs(0,1)]\n",
    "alpha_k = [scipy.stats.norm.rvs(0,1)]\n",
    "sigma_square_k = [scipy.stats.invgauss.rvs(a_sigma_k[-1],b_sigma_k[-1])]\n",
    "\n",
    "mu2_k = [scipy.stats.norm.rvs(0,1)]\n",
    "sigma2_square_k = [scipy.stats.invgauss.rvs(a_sigma2_k[-1],b_sigma2_k[-1])]\n",
    "\n",
    "posteriors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE POSTERIOR\n",
    "\n",
    "def compute_posterior(linked_records, z, theta_m, theta_u, alpha_pi, beta_pi, sigma_square, a_sigma, b_sigma, beta0, beta1, alpha, mu2, sigma2_square, a_sigma2, b_sigma2):\n",
    "    result = 0\n",
    "    # likelihood 1\n",
    "    # need linked_records computed based on z\n",
    "    Y = np.array(linked_records.Y)\n",
    "    X = np.array([linked_records.propensity_score*linked_records.treatment, linked_records.propensity_score])\n",
    "    X = sm.add_constant(X)\n",
    "    X = X.T\n",
    "    model = sm.GLM(Y,X)\n",
    "    results = model.fit()\n",
    "    residuals = Y - X @ results.params\n",
    "    estimated_variance = residuals.T @ residuals / (len(residuals) - (X.shape[1]+1))\n",
    "    result += np.log(scipy.stats.norm.pdf(residuals, 0, np.sqrt(estimated_variance))).sum()\n",
    "    # likelihood 2\n",
    "    # need z\n",
    "    Y = scipy.stats.norm.rvs(mu2, np.sqrt(sigma2_square), size=len(z[z<0]))\n",
    "    result += np.log(scipy.stats.norm.pdf(Y, mu2, np.sqrt(sigma2_square))).sum()\n",
    "    # likelihood 3 and 4\n",
    "    # need AB, z, theta_m, theta_u ATTENTION AB SHOULD BE KNOWN (GLOBAL)\n",
    "    idx_A = z[z>=0]\n",
    "    idx_B = np.nonzero(z>=0)[0]\n",
    "    links = pds.MultiIndex.from_tuples(zip(idx_A,idx_B))\n",
    "    pairs = pds.MultiIndex.from_frame(AB[[\"source_index_A\", \"source_index_B\"]])\n",
    "    # 3\n",
    "    data = AB[pairs.isin(links)] # 1-2-1 matches enforced by construction of z\n",
    "    pattern_match, count_match = np.unique(data.filter(regex=\"comparison\"), return_counts=True, axis=0)\n",
    "    result += ((pattern_match @ np.log(theta_m) + (1-pattern_match) @ np.log(1-theta_m)) * count_match).sum()\n",
    "    # 4\n",
    "    data = AB[(~AB.source_index_B.duplicated())&(~pairs.isin(links))] # enforce 1-2-1 by removing duplicata\n",
    "    pattern_unmatch, count_unmatch = np.unique(data.filter(regex=\"comparison\"), return_counts=True, axis=0)\n",
    "    result += ((pattern_unmatch @ np.log(theta_u) + (1-pattern_unmatch) @ np.log(1-theta_u)) * count_unmatch).sum()\n",
    "    # prior 1\n",
    "    # need z, alpha_pi, beta_pi\n",
    "    n_AB = (z>=0).sum()\n",
    "    result += math.log(math.factorial(A.shape[0]-n_AB)) - math.log(math.factorial(A.shape[0])) + scipy.special.betaln(n_AB + alpha_pi, B.shape[0] - n_AB + beta_pi) - scipy.special.betaln(alpha_pi, beta_pi)\n",
    "    # prior 2\n",
    "    # need theta_m QUESTION a-1 / b-1?\n",
    "    result += (1 * np.log(theta_m) + 1 * np.log(1-theta_m)).sum()\n",
    "    # prior 3\n",
    "    # need theta_u QUESTION a-1 / b-1?\n",
    "    result += (1 * np.log(theta_u) + 1 * np.log(1-theta_u)).sum()\n",
    "    # prior 4\n",
    "    # need sigma_square, a_sigma, b_sigma QUESTION unclear if it is the pdf?\n",
    "    result += np.log(scipy.stats.invgauss.pdf(sigma_square, a_sigma, b_sigma))\n",
    "    # prior 5\n",
    "    # need beta0, beta1, alpha QUESTION unclear if it is the pdf?\n",
    "    result += np.log(scipy.stats.multivariate_normal.pdf([beta0, beta1, alpha], [0,0,0], np.eye(3)))\n",
    "    # prior 6\n",
    "    # need mu2 QUESTION unclear if it is the pdf?\n",
    "    result += np.log(scipy.stats.norm.pdf(mu2, 0, 1))\n",
    "    # prior 7\n",
    "    # need sigma2_square, a_sigma2, b_sigma2 QUESTION unclear if it is the pdf?\n",
    "    result += np.log(scipy.stats.invgauss.pdf(sigma2_square, a_sigma2, b_sigma2))\n",
    "    return result\n",
    "\n",
    "posterior = compute_posterior(linked_records_k[-1], z_k[-1], theta_m_k[-1], theta_u_k[-1], alpha_pi_k[-1], beta_pi_k[-1], sigma_square_k[-1], a_sigma_k[-1], b_sigma_k[-1], beta0_k[-1], beta1_k[-1], alpha_k[-1], mu2_k[-1], sigma2_square_k[-1], a_sigma2_k[-1], b_sigma2_k[-1])\n",
    "posteriors.append(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.240693\n",
      "         Iterations 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kayane/anaconda3/envs/tester/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/kayane/anaconda3/envs/tester/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# COMPUTE PROPOSAL\n",
    "\n",
    "def compute_proposal(z, sigma_square, a_sigma, b_sigma, beta0, beta1, alpha, mu2, sigma2_square, a_sigma2, b_sigma2):\n",
    "    result = [] # z, linked_records, theta_m, theta_u, beta0, beta1, alpha, sigma_square, mu2, sigma2_square\n",
    "    # z\n",
    "    linked_record_prop = (z<B.shape[0]).sum() / len(z) # proportion of linked records in previous z\n",
    "    new = np.random.choice(A.shape[0], size=B.shape[0], replace=False)\n",
    "    new = new * np.random.choice([1,-1], size=B.shape[0], p=[linked_record_prop, 1-linked_record_prop]) # randomly set negative some values so that the proportion of positive values corresponds to linked_record_prop\n",
    "    result.append(new)\n",
    "    # linked records\n",
    "    idx_A = z[z>=0]\n",
    "    idx_B = np.nonzero(z>=0)[0]\n",
    "    from_A = A.iloc[idx_A,:].reset_index(drop=True)\n",
    "    from_B = B.iloc[idx_B,:].reset_index(drop=True)\n",
    "    linked_records = pds.concat([from_B, from_A.Y], axis=1)\n",
    "    linked_records['propensity_score'] = propensity_score(linked_records, covariates, None, False)\n",
    "    result.append(linked_records)\n",
    "    # theta_m QUESTION we do not care of dependence on previous param\n",
    "    links = pds.MultiIndex.from_tuples(zip(idx_A,idx_B))\n",
    "    pairs = pds.MultiIndex.from_frame(AB[[\"source_index_A\", \"source_index_B\"]])\n",
    "    comparisons = AB[pairs.isin(links)].filter(regex=\"comparison\")\n",
    "    match = comparisons.sum(axis=0) / len(comparisons)\n",
    "    result.append(match)\n",
    "    # theta_u QUESTION we do not care of dependence on previous param\n",
    "    comparisons = AB.filter(regex=\"comparison\")\n",
    "    unmatch = comparisons.sum(axis=0) / len(comparisons)\n",
    "    result.append(unmatch)\n",
    "    # beta0, beta1, alpha, sigma_square\n",
    "    result.append(beta0+scipy.stats.norm.rvs(0,0.5))\n",
    "    result.append(beta1+scipy.stats.norm.rvs(0,0.5))\n",
    "    result.append(alpha+scipy.stats.norm.rvs(0,0.5))\n",
    "    result.append(sigma_square+scipy.stats.invgauss.rvs(a_sigma,b_sigma))\n",
    "    # mu2, sigma2_square\n",
    "    result.append(mu2+scipy.stats.norm.rvs(0,1))\n",
    "    result.append(sigma2_square+scipy.stats.invgauss.rvs(a_sigma2,b_sigma2))\n",
    "    return result\n",
    "\n",
    "proposal = compute_proposal(z_k[-1], sigma_square_k[-1], a_sigma_k[-1], b_sigma_k[-1], beta0_k[-1], beta1_k[-1], alpha_k[-1], mu2_k[-1], sigma2_square_k[-1], a_sigma2_k[-1], b_sigma2_k[-1])\n",
    "new_z, new_linked_records, new_theta_m, new_theta_u, new_beta0, new_beta1, new_alpha, new_sigma_square, new_mu2, new_sigma2_square = proposal\n",
    "\n",
    "new_posterior = compute_posterior(new_linked_records, new_z, new_theta_m, new_theta_u, alpha_pi_k[-1], beta_pi_k[-1], new_sigma_square, a_sigma_k[-1], b_sigma_k[-1], new_beta0, new_beta1, new_alpha, new_mu2, new_sigma2_square, a_sigma2_k[-1], b_sigma2_k[-1])\n",
    "posteriors.append(new_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = scipy.stats.uniform.rvs(0,1)\n",
    "if U < posteriors[-1] / posteriors[-2]:\n",
    "    z_k.append(new_z)\n",
    "    linked_records_k.append(new_linked_records)\n",
    "    theta_m_k.append(new_theta_m)\n",
    "    theta_u_k.append(new_theta_u)\n",
    "    beta0_k.append(beta0)\n",
    "    beta1_k.append(beta1)\n",
    "    alpha_k.append(new_alpha)\n",
    "    sigma_square_k.append(new_sigma_square)\n",
    "    mu2_k.append(new_mu2)\n",
    "    sigma2_square_k.append(new_sigma2_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION EST CE QU IL FAUT: NE PAS LES FAIRE TOUS EN MEME TEMPS MAIS 1 PAR 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.843309640884399"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3593661589996669"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INITIAL POSTERIOR\n",
    "\n",
    "# likelihood 1\n",
    "# need linked_records computed based on z\n",
    "Y = np.array(linked_records_k[-1].Y)\n",
    "X = np.array([linked_records_k[-1].propensity_score*linked_records_k[-1].treatment, linked_records_k[-1].propensity_score])\n",
    "X = sm.add_constant(X)\n",
    "X = X.T\n",
    "model = sm.GLM(Y,X)\n",
    "results = model.fit()\n",
    "residuals = Y - X @ results.params\n",
    "estimated_variance = residuals.T @ residuals / (len(residuals) - (X.shape[1]+1))\n",
    "np.log(scipy.stats.norm.pdf(residuals, 0, np.sqrt(estimated_variance))).sum()\n",
    "\n",
    "# likelihood 2\n",
    "# need z\n",
    "Y = scipy.stats.norm.rvs(mu2_k[-1], np.sqrt(sigma2_square_k[-1]), size=len(z_k[-1][z_k[-1]<0]))\n",
    "np.log(scipy.stats.norm.pdf(Y, mu2_k[-1], np.sqrt(sigma2_square_k[-1]))).sum()\n",
    "\n",
    "# likelihood 3 and 4\n",
    "# need AB, z, theta_m, theta_u ATTENTION AB SHOULD BE KNOWN (GLOBAL)\n",
    "idx_A = z_k[-1][z_k[-1]>=0]\n",
    "idx_B = np.nonzero(z_k[-1]>=0)[0]\n",
    "links = pds.MultiIndex.from_tuples(zip(idx_A,idx_B))\n",
    "pairs = pds.MultiIndex.from_frame(AB[[\"source_index_A\", \"source_index_B\"]])\n",
    "# 3\n",
    "data = AB[pairs.isin(links)]\n",
    "pattern_match, count_match = np.unique(data.filter(regex=\"comparison\"), return_counts=True, axis=0)\n",
    "((pattern_match @ np.log(theta_m_k[-1]) + (1-pattern_match) @ np.log(1-theta_m_k[-1])) * count_match).sum()\n",
    "# 4\n",
    "data = AB[~pairs.isin(links)]\n",
    "pattern_unmatch, count_unmatch = np.unique(data.filter(regex=\"comparison\"), return_counts=True, axis=0)\n",
    "((pattern_unmatch @ np.log(theta_u_k[-1]) + (1-pattern_unmatch) @ np.log(1-theta_u_k[-1])) * count_unmatch).sum()\n",
    "\n",
    "# prior 1\n",
    "# need z, alpha_pi, beta_pi\n",
    "n_AB = (z_k[-1]>=0).sum()\n",
    "math.log(math.factorial(A.shape[0]-n_AB)) - math.log(math.factorial(A.shape[0])) + scipy.special.betaln(n_AB + alpha_pi_k[-1], B.shape[0] - n_AB + beta_pi_k[-1]) - scipy.special.betaln(alpha_pi_k[-1], beta_pi_k[-1])\n",
    "\n",
    "# prior 2\n",
    "# need theta_m QUESTION a-1 / b-1?\n",
    "(1 * np.log(theta_m_k[-1]) + 1 * np.log(1-theta_m_k[-1])).sum()\n",
    "\n",
    "# prior 3\n",
    "# need theta_u QUESTION a-1 / b-1?\n",
    "(1 * np.log(theta_u_k[-1]) + 1 * np.log(1-theta_u_k[-1])).sum()\n",
    "\n",
    "# prior 4\n",
    "# need sigma_square, a_sigma, b_sigma QUESTION unclear if it is the pdf?\n",
    "np.log(scipy.stats.invgauss.pdf(sigma_square_k[-1], a_sigma_k[-1], b_sigma_k[-1]))\n",
    "\n",
    "# prior 5\n",
    "# need beta0, beta1, alpha QUESTION unclear if it is the pdf?\n",
    "np.log(scipy.stats.multivariate_normal.pdf([beta0_k[-1], beta1_k[-1], alpha_k[-1]], [0,0,0], np.eye(3)))\n",
    "\n",
    "# prior 6\n",
    "# need mu2 QUESTION unclear if it is the pdf?\n",
    "np.log(scipy.stats.norm.pdf(mu2_k[-1], 0, 1))\n",
    "\n",
    "# prior 7\n",
    "# need sigma2_square, a_sigma2, b_sigma2 QUESTION unclear if it is the pdf?\n",
    "np.log(scipy.stats.invgauss.pdf(sigma2_square_k[-1], a_sigma2_k[-1], b_sigma2_k[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.218068\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "# PROPOSALS\n",
    "\n",
    "# z\n",
    "linked_record_prop = (z_k[-1]<B.shape[0]).sum() / len(z_k[-1]) # proportion of linked records in previous z\n",
    "new = np.random.choice(A.shape[0], size=B.shape[0], replace=False)\n",
    "new = new * np.random.choice([1,-1], size=B.shape[0], p=[linked_record_prop, 1-linked_record_prop]) # randomly set negative some values so that the proportion of positive values corresponds to linked_record_prop\n",
    "z_k.append(new)\n",
    "\n",
    "# linked records\n",
    "idx_A = z_k[-1][z_k[-1]>=0]\n",
    "idx_B = np.nonzero(z_k[-1]>=0)[0]\n",
    "from_A = A.iloc[idx_A,:].reset_index(drop=True)\n",
    "from_B = B.iloc[idx_B,:].reset_index(drop=True)\n",
    "linked_records = pds.concat([from_B, from_A.Y], axis=1)\n",
    "linked_records['propensity_score'] = propensity_score(linked_records, covariates, None, False)\n",
    "linked_records_k = [linked_records]\n",
    "\n",
    "# theta_m QUESTION we do not care of dependence on previous param\n",
    "links = pds.MultiIndex.from_tuples(zip(idx_A,idx_B))\n",
    "pairs = pds.MultiIndex.from_frame(AB[[\"source_index_A\", \"source_index_B\"]])\n",
    "comparisons = AB[pairs.isin(links)].filter(regex=\"comparison\")\n",
    "match = comparisons.sum(axis=0) / len(comparisons)\n",
    "theta_m_k.append(match)\n",
    "\n",
    "# theta_u QUESTION we do not care of dependence on previous param\n",
    "comparisons = AB.filter(regex=\"comparison\")\n",
    "unmatch = comparisons.sum(axis=0) / len(comparisons)\n",
    "theta_u_k.append(unmatch)\n",
    "\n",
    "# beta0, beta1, alpha, sigma_square\n",
    "beta0_k.append(beta0_k[-1]+scipy.stats.norm.rvs(0,0.5))\n",
    "beta1_k.append(beta1_k[-1]+scipy.stats.norm.rvs(0,0.5))\n",
    "alpha_k.append(alpha_k[-1]+scipy.stats.norm.rvs(0,0.5))\n",
    "sigma_square_k.append(sigma_square_k[-1]+scipy.stats.invgauss.rvs(a_sigma_k[-1],b_sigma_k[-1]))\n",
    "\n",
    "# mu2, sigma2_square\n",
    "mu2_k.append(mu2_k[-1]+scipy.stats.norm.rvs(0,1))\n",
    "sigma2_square_k.append(sigma2_square_k[-1]+scipy.stats.invgauss.rvs(a_sigma2_k[-1],b_sigma2_k[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theta_m' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/kayane/Documents/Code/PhD/GitHub/PhD-research/replicate Guha/bay_CI_RL.ipynb Cell 41\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kayane/Documents/Code/PhD/GitHub/PhD-research/replicate%20Guha/bay_CI_RL.ipynb#X64sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m data \u001b[39m=\u001b[39m AB[pairs\u001b[39m.\u001b[39misin(links)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kayane/Documents/Code/PhD/GitHub/PhD-research/replicate%20Guha/bay_CI_RL.ipynb#X64sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m pattern_match, count_match \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(data\u001b[39m.\u001b[39mfilter(regex\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcomparison\u001b[39m\u001b[39m\"\u001b[39m), return_counts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kayane/Documents/Code/PhD/GitHub/PhD-research/replicate%20Guha/bay_CI_RL.ipynb#X64sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m ((pattern_match \u001b[39m@\u001b[39m np\u001b[39m.\u001b[39mlog(theta_m) \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mpattern_match) \u001b[39m@\u001b[39m np\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mtheta_m)) \u001b[39m*\u001b[39m count_match)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kayane/Documents/Code/PhD/GitHub/PhD-research/replicate%20Guha/bay_CI_RL.ipynb#X64sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# 4\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kayane/Documents/Code/PhD/GitHub/PhD-research/replicate%20Guha/bay_CI_RL.ipynb#X64sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m data \u001b[39m=\u001b[39m AB[\u001b[39m~\u001b[39mpairs\u001b[39m.\u001b[39misin(links)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'theta_m' is not defined"
     ]
    }
   ],
   "source": [
    "# NEW POSTERIOR:\n",
    "\n",
    "# likelihood 1\n",
    "# need linked_records computed based on z\n",
    "Y = np.array(linked_records_k[-1].Y)\n",
    "X = np.array([linked_records_k[-1].propensity_score*linked_records_k[-1].treatment, linked_records_k[-1].propensity_score])\n",
    "X = sm.add_constant(X)\n",
    "X = X.T\n",
    "model = sm.GLM(Y,X)\n",
    "results = model.fit()\n",
    "residuals = Y - X @ results.params\n",
    "estimated_variance = residuals.T @ residuals / (len(residuals) - (X.shape[1]+1))\n",
    "np.log(scipy.stats.norm.pdf(residuals, 0, np.sqrt(estimated_variance))).sum()\n",
    "\n",
    "# likelihood 2\n",
    "# need z\n",
    "Y = scipy.stats.norm.rvs(mu2_k[-1], np.sqrt(sigma2_square_k[-1]), size=len(z_k[-1][z_k[-1]<0]))\n",
    "np.log(scipy.stats.norm.pdf(Y, mu2_k[-1], np.sqrt(sigma2_square_k[-1]))).sum()\n",
    "\n",
    "# likelihood 3 and 4\n",
    "# need AB, z, theta_m, theta_u ATTENTION AB SHOULD BE KNOWN (GLOBAL)\n",
    "idx_A = z_k[-1][z_k[-1]>=0]\n",
    "idx_B = np.nonzero(z_k[-1]>=0)[0]\n",
    "links = pds.MultiIndex.from_tuples(zip(idx_A,idx_B))\n",
    "pairs = pds.MultiIndex.from_frame(AB[[\"source_index_A\", \"source_index_B\"]])\n",
    "# 3\n",
    "data = AB[pairs.isin(links)]\n",
    "pattern_match, count_match = np.unique(data.filter(regex=\"comparison\"), return_counts=True, axis=0)\n",
    "((pattern_match @ np.log(theta_m_k[-1]) + (1-pattern_match) @ np.log(1-theta_m_k[-1])) * count_match).sum()\n",
    "# 4\n",
    "data = AB[~pairs.isin(links)]\n",
    "pattern_unmatch, count_unmatch = np.unique(data.filter(regex=\"comparison\"), return_counts=True, axis=0)\n",
    "((pattern_unmatch @ np.log(theta_u_k[-1]) + (1-pattern_unmatch) @ np.log(1-theta_u_k[-1])) * count_unmatch).sum()\n",
    "\n",
    "# prior 1\n",
    "# need z, alpha_pi, beta_pi\n",
    "n_AB = (z_k[-1]>=0).sum()\n",
    "math.log(math.factorial(A.shape[0]-n_AB)) - math.log(math.factorial(A.shape[0])) + scipy.special.betaln(n_AB + alpha_pi_k[-1], B.shape[0] - n_AB + beta_pi_k[-1]) - scipy.special.betaln(alpha_pi_k[-1], beta_pi_k[-1])\n",
    "\n",
    "# prior 2\n",
    "# need theta_m QUESTION a-1 / b-1?\n",
    "(1 * np.log(theta_m_k[-1]) + 1 * np.log(1-theta_m_k[-1])).sum()\n",
    "\n",
    "# prior 3\n",
    "# need theta_u QUESTION a-1 / b-1?\n",
    "(1 * np.log(theta_u_k[-1]) + 1 * np.log(1-theta_u_k[-1])).sum()\n",
    "\n",
    "# prior 4\n",
    "# need sigma_quare, a_sigma, b_sigma QUESTION unclear if it is the pdf?\n",
    "np.log(scipy.stats.invgauss.pdf(sigma_square_k[-1], a_sigma_k[-1], b_sigma_k[-1]))\n",
    "\n",
    "# prior 5\n",
    "# need beta0, beta1, alpha QUESTION unclear if it is the pdf?\n",
    "np.log(scipy.stats.multivariate_normal.pdf([beta0_k[-1], beta1_k[-1], alpha_k[-1]], [0,0,0], np.eye(3)))\n",
    "\n",
    "# prior 6\n",
    "# need mu2 QUESTION unclear if it is the pdf?\n",
    "np.log(scipy.stats.norm.pdf(mu2_k[-1], 0, 1))\n",
    "\n",
    "# prior 7\n",
    "# need sigma2_square, a_sigma2, b_sigma2 QUESTION unclear if it is the pdf?\n",
    "np.log(scipy.stats.invgauss.pdf(sigma2_square_k[-1], a_sigma2_k[-1], b_sigma2_k[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tester",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b95706f4894ee4355943f31879e0e3a76d825289e1bc7e0d16bc1dcbc4ba3b09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
